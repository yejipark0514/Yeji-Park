{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9bca19-304d-477f-a2fd-c889f39b9a1c",
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1712785294190,
     "user": {
      "displayName": "Natalie Chow",
      "userId": "09441291420282620726"
     },
     "user_tz": 240
    },
    "id": "ce1e4fac-65a3-4448-a81e-92e7651486e5"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab2726d-608a-485e-bb0f-c3a062129c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3037dc8a-11e2-48f4-b0e5-3e9e3a160c01",
   "metadata": {
    "id": "3037dc8a-11e2-48f4-b0e5-3e9e3a160c01"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col, column, when, avg, mean\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import array_contains, array_position\n",
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f84981-7b1e-44c8-87e4-75a0a015fb5e",
   "metadata": {
    "id": "84f84981-7b1e-44c8-87e4-75a0a015fb5e"
   },
   "outputs": [],
   "source": [
    "ss=SparkSession.builder.appName(\"DS410 Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d8b9ec-a664-4758-ad88-7e0835d7f3eb",
   "metadata": {
    "id": "71d8b9ec-a664-4758-ad88-7e0835d7f3eb"
   },
   "outputs": [],
   "source": [
    "ss.sparkContext.setCheckpointDir(\"~/scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca03947e-8a19-404c-bff0-834c77652d80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2402,
     "status": "ok",
     "timestamp": 1712785403938,
     "user": {
      "displayName": "Natalie Chow",
      "userId": "09441291420282620726"
     },
     "user_tz": 240
    },
    "id": "ca03947e-8a19-404c-bff0-834c77652d80",
    "outputId": "d7348579-7f67-4bbf-d54d-87d79aed2286"
   },
   "outputs": [],
   "source": [
    "df = ss.read.csv(\"/storage/home/trn5106/work/Final Project/main code/water_quality_large.csv\", header=True, inferSchema=True) # Make sure to use the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37073dd-f21e-4f7b-89b1-b265253b08ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1712785411347,
     "user": {
      "displayName": "Natalie Chow",
      "userId": "09441291420282620726"
     },
     "user_tz": 240
    },
    "id": "f37073dd-f21e-4f7b-89b1-b265253b08ad",
    "outputId": "26fbe79b-3ba2-4daa-c541-a77d0d3d870f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39868a5f-7f6b-4439-ad3d-5261f4250ef3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "error",
     "timestamp": 1712785419001,
     "user": {
      "displayName": "Natalie Chow",
      "userId": "09441291420282620726"
     },
     "user_tz": 240
    },
    "id": "39868a5f-7f6b-4439-ad3d-5261f4250ef3",
    "outputId": "6d0c510f-f188-47af-adc0-e0bc43f3f4d5"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `ResultMeasureUnits` cannot be resolved. Did you mean one of the following? [`ResultMeasureValue`, `ResultFileUrl`, `ResultCommentText`, `ResultTimeBasisText`, `ResultIdentifier`].;\n'Project [ActivityStartDate#23, MonitoringLocationIdentifier#40, CharacteristicName#56, ResultMeasureValue#58, HydrologicEvent#45, 'ResultMeasureUnits]\n+- Relation [OrganizationIdentifier#17,OrganizationFormalName#18,ActivityIdentifier#19,ActivityTypeCode#20,ActivityMediaName#21,ActivityMediaSubdivisionName#22,ActivityStartDate#23,ActivityStartTime/Time#24,ActivityStartTime/TimeZoneCode#25,ActivityEndDate#26,ActivityEndTime/Time#27,ActivityEndTime/TimeZoneCode#28,ActivityRelativeDepthName#29,ActivityDepthHeightMeasure/MeasureValue#30,ActivityDepthHeightMeasure/MeasureUnitCode#31,ActivityDepthAltitudeReferencePointText#32,ActivityTopDepthHeightMeasure/MeasureValue#33,ActivityTopDepthHeightMeasure/MeasureUnitCode#34,ActivityBottomDepthHeightMeasure/MeasureValue#35,ActivityBottomDepthHeightMeasure/MeasureUnitCode#36,ProjectIdentifier#37,ProjectName#38,ActivityConductingOrganizationText#39,MonitoringLocationIdentifier#40,... 57 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-03716155ac56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ActivityStartDate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"MonitoringLocationIdentifier\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CharacteristicName\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ResultMeasureValue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HydrologicEvent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ResultMeasureUnits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3221\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3222\u001b[0m         \"\"\"\n\u001b[0;32m-> 3223\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `ResultMeasureUnits` cannot be resolved. Did you mean one of the following? [`ResultMeasureValue`, `ResultFileUrl`, `ResultCommentText`, `ResultTimeBasisText`, `ResultIdentifier`].;\n'Project [ActivityStartDate#23, MonitoringLocationIdentifier#40, CharacteristicName#56, ResultMeasureValue#58, HydrologicEvent#45, 'ResultMeasureUnits]\n+- Relation [OrganizationIdentifier#17,OrganizationFormalName#18,ActivityIdentifier#19,ActivityTypeCode#20,ActivityMediaName#21,ActivityMediaSubdivisionName#22,ActivityStartDate#23,ActivityStartTime/Time#24,ActivityStartTime/TimeZoneCode#25,ActivityEndDate#26,ActivityEndTime/Time#27,ActivityEndTime/TimeZoneCode#28,ActivityRelativeDepthName#29,ActivityDepthHeightMeasure/MeasureValue#30,ActivityDepthHeightMeasure/MeasureUnitCode#31,ActivityDepthAltitudeReferencePointText#32,ActivityTopDepthHeightMeasure/MeasureValue#33,ActivityTopDepthHeightMeasure/MeasureUnitCode#34,ActivityBottomDepthHeightMeasure/MeasureValue#35,ActivityBottomDepthHeightMeasure/MeasureUnitCode#36,ProjectIdentifier#37,ProjectName#38,ActivityConductingOrganizationText#39,MonitoringLocationIdentifier#40,... 57 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "df2 = df.select(\"ActivityStartDate\",\"MonitoringLocationIdentifier\",\"CharacteristicName\", \"ResultMeasureValue\", \"HydrologicEvent\", \"ResultMeasureUnits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b6afd-5b5b-47bb-960e-b6fa6df2c764",
   "metadata": {
    "id": "524b6afd-5b5b-47bb-960e-b6fa6df2c764",
    "outputId": "0c514669-c018-40ba-e2c3-ac5fb709a688"
   },
   "outputs": [],
   "source": [
    "#df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75309b3a-8533-45e8-9241-ada896e4e3e6",
   "metadata": {
    "id": "75309b3a-8533-45e8-9241-ada896e4e3e6",
    "outputId": "91b04dbb-4cb6-45fd-898c-2913bbe5a3b3"
   },
   "outputs": [],
   "source": [
    "#df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63491d02-98a9-48a8-84f6-f6b1946a9a89",
   "metadata": {
    "id": "63491d02-98a9-48a8-84f6-f6b1946a9a89"
   },
   "outputs": [],
   "source": [
    "df3 = df2.filter(col(\"ActivityStartDate\").isNotNull())\n",
    "df4 = df3.filter(col(\"MonitoringLocationIdentifier\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d6267-aebd-4fa2-a9e7-986038473d55",
   "metadata": {
    "id": "864d6267-aebd-4fa2-a9e7-986038473d55",
    "outputId": "d69f7408-f9ed-4a59-ada0-bfec118707e8"
   },
   "outputs": [],
   "source": [
    "#df4.filter(col(\"CharacteristicName\") == \"Temperature, water\").select(\"ResultMeasure/MeasureUnitCode\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8c20b-77dc-4541-8be1-cd31540b1a26",
   "metadata": {
    "id": "87d8c20b-77dc-4541-8be1-cd31540b1a26",
    "outputId": "2b87f060-f3fd-4f7b-ea56-38cb6cd1c3a9"
   },
   "outputs": [],
   "source": [
    "#df4.filter(col(\"CharacteristicName\") == \"Temperature, water\").groupBy(\"ResultMeasure/MeasureUnitCode\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206b9ad-9655-4a59-9248-178c80446a90",
   "metadata": {
    "id": "f206b9ad-9655-4a59-9248-178c80446a90",
    "outputId": "ad999ae9-0cd8-42ab-fdde-84c253e0bf4a"
   },
   "outputs": [],
   "source": [
    "#df4.filter(col(\"CharacteristicName\") == \"Oxygen\").groupBy(\"ResultMeasure/MeasureUnitCode\").count().show()\n",
    "#df4.filter(col(\"CharacteristicName\") == \"Oxygen\").filter(col(\"ResultMeasure/MeasureUnitCode\") == \"mg/l\").select(\"ResultMeasureValue\").summary().show()\n",
    "#df4.filter(col(\"CharacteristicName\") == \"Oxygen\").filter(col(\"ResultMeasure/MeasureUnitCode\") == \"% saturatn\").select(\"ResultMeasureValue\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fe2d4-3de6-4146-8533-f67cac608c8e",
   "metadata": {
    "id": "589fe2d4-3de6-4146-8533-f67cac608c8e",
    "outputId": "5e2789ae-be1a-4510-97e6-9cd64064f49a"
   },
   "outputs": [],
   "source": [
    "#df4.filter(col(\"CharacteristicName\") == \"Specific conductance\").groupBy(\"ResultMeasure/MeasureUnitCode\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d59a2-b7f9-4b36-aa09-c72e15d4541d",
   "metadata": {
    "id": "557d59a2-b7f9-4b36-aa09-c72e15d4541d",
    "outputId": "d9078982-f400-4076-fd3a-f0c4cc1dc4df"
   },
   "outputs": [],
   "source": [
    "#df4.filter(col(\"CharacteristicName\") == \"pH\").groupBy(\"ResultMeasure/MeasureUnitCode\").count().show()\n",
    "#df4.filter(col(\"CharacteristicName\") == \"pH\").filter(col(\"ResultMeasure/MeasureUnitCode\") == \"None\").select(\"ResultMeasureValue\").summary().show()\n",
    "#df4.filter(col(\"CharacteristicName\") == \"pH\").filter(col(\"ResultMeasure/MeasureUnitCode\") == \"std units\").select(\"ResultMeasureValue\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f27d82-99da-4e2c-b969-604500c56c0a",
   "metadata": {
    "id": "95f27d82-99da-4e2c-b969-604500c56c0a"
   },
   "outputs": [],
   "source": [
    "#temp = df4.filter(col(\"CharacteristicName\") == \"pH\")\n",
    "#temp = df4.filter(col(\"ResultMeasure/MeasureUnitCode\") == \"std units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b65c5-6c26-4c78-befa-70b6a3fde3d7",
   "metadata": {
    "id": "a79b65c5-6c26-4c78-befa-70b6a3fde3d7"
   },
   "outputs": [],
   "source": [
    "#temp = temp.withColumn(\"pH\", temp[\"ResultMeasureValue\"].cast(FloatType())).select(\"pH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bd257-7028-47ae-900b-cf82043fcf31",
   "metadata": {
    "id": "507bd257-7028-47ae-900b-cf82043fcf31",
    "outputId": "a5e04e84-d7a5-478d-99f7-17ca2ea9923c"
   },
   "outputs": [],
   "source": [
    "#temp.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531d82c-77d6-4bef-b8ea-3b98fcf53095",
   "metadata": {
    "id": "d531d82c-77d6-4bef-b8ea-3b98fcf53095"
   },
   "outputs": [],
   "source": [
    "df4 = df4.filter((col(\"HydrologicEvent\") == \"Storm\") | (col(\"HydrologicEvent\") == \"Routine sample\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae296730-ec47-4c91-a27d-0e6e2363311c",
   "metadata": {
    "id": "ae296730-ec47-4c91-a27d-0e6e2363311c"
   },
   "outputs": [],
   "source": [
    "df4 = df4.filter((col(\"ResultMeasureUnits\") == \"std units\") |\\\n",
    "                (col(\"ResultMeasureUnits\") == \"deg C\") |\\\n",
    "                (col(\"ResultMeasureUnits\") == \"mg/l\") |\\\n",
    "                (col(\"ResultMeasureUnits\") == \"uS/cm @25C\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0194c3-bb7f-4694-a75b-ab342ed8f9b6",
   "metadata": {
    "id": "6b0194c3-bb7f-4694-a75b-ab342ed8f9b6"
   },
   "outputs": [],
   "source": [
    "df_characteristic = df4.groupBy(\"ActivityStartDate\", \"MonitoringLocationIdentifier\").agg(collect_list(\"CharacteristicName\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191173f0-faae-46e7-bd9a-209a032fe8d7",
   "metadata": {
    "id": "191173f0-faae-46e7-bd9a-209a032fe8d7"
   },
   "outputs": [],
   "source": [
    "df_value = df4.groupBy(\"ActivityStartDate\", \"MonitoringLocationIdentifier\").agg(collect_list(\"ResultMeasureValue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b65159-9fa2-4baf-a0d0-b333847d2eda",
   "metadata": {
    "id": "59b65159-9fa2-4baf-a0d0-b333847d2eda"
   },
   "outputs": [],
   "source": [
    "df_hydro_event = df4.groupBy(\"ActivityStartDate\", \"MonitoringLocationIdentifier\").agg(collect_list(\"HydrologicEvent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2620b-a62d-4098-9483-01c7c52724de",
   "metadata": {
    "id": "7ef2620b-a62d-4098-9483-01c7c52724de"
   },
   "outputs": [],
   "source": [
    "df5 = df_characteristic.join(df_value, [\"ActivityStartDate\", \"MonitoringLocationIdentifier\"])\\\n",
    ".join(df_hydro_event, [\"ActivityStartDate\", \"MonitoringLocationIdentifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0304f-726d-4e79-ad9e-e06556e65a20",
   "metadata": {
    "id": "2be0304f-726d-4e79-ad9e-e06556e65a20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04d207-191e-4900-9273-05a1d06a0628",
   "metadata": {
    "id": "9c04d207-191e-4900-9273-05a1d06a0628"
   },
   "outputs": [],
   "source": [
    "features = [\"Temperature, water\", \"Specific conductance\", \"pH\", \"Oxygen\", \"HydrologicEvent\", \"ResultMeasure/MeasureUnitCode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569811a0-cf67-4f8b-abb5-27c63b9fb190",
   "metadata": {
    "id": "569811a0-cf67-4f8b-abb5-27c63b9fb190"
   },
   "outputs": [],
   "source": [
    "df6 = df5.withColumn(features[0],\\\n",
    "                     when(array_position(\"collect_list(CharacteristicName)\", features[0]) != 0,\\\n",
    "                         col(\"collect_list(ResultMeasureValue)\")[array_position(\"collect_list(CharacteristicName)\", features[0]) - 1]\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88017d91-74da-48f8-a226-83b8454e03d4",
   "metadata": {
    "id": "88017d91-74da-48f8-a226-83b8454e03d4"
   },
   "outputs": [],
   "source": [
    "df7 = df6.withColumn(features[1],\\\n",
    "                     when(array_position(\"collect_list(CharacteristicName)\", features[1]) != 0,\\\n",
    "                         col(\"collect_list(ResultMeasureValue)\")[array_position(\"collect_list(CharacteristicName)\", features[1]) - 1]\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afec95-dfdf-40e4-8fef-f92c9faec23b",
   "metadata": {
    "id": "71afec95-dfdf-40e4-8fef-f92c9faec23b"
   },
   "outputs": [],
   "source": [
    "df8 = df7.withColumn(features[2],\\\n",
    "                     when(array_position(\"collect_list(CharacteristicName)\", features[2]) != 0,\\\n",
    "                         col(\"collect_list(ResultMeasureValue)\")[array_position(\"collect_list(CharacteristicName)\", features[2]) - 1]\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e16c2-1671-413a-aeb5-514ea851ec2c",
   "metadata": {
    "id": "791e16c2-1671-413a-aeb5-514ea851ec2c"
   },
   "outputs": [],
   "source": [
    "df9 = df8.withColumn(features[3],\\\n",
    "                     when(array_position(\"collect_list(CharacteristicName)\", features[3]) != 0,\\\n",
    "                         col(\"collect_list(ResultMeasureValue)\")[array_position(\"collect_list(CharacteristicName)\", features[3]) - 1]\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ca45a-fcbb-4bb1-9f7f-ade5c0367e0f",
   "metadata": {
    "id": "6f7ca45a-fcbb-4bb1-9f7f-ade5c0367e0f"
   },
   "outputs": [],
   "source": [
    "df10 = df9.withColumn(features[4],\\\n",
    "                     when(array_position(\"collect_list(HydrologicEvent)\", \"Storm\") != 0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38079ca3-5640-4adf-b844-1d80a0b146ce",
   "metadata": {
    "id": "38079ca3-5640-4adf-b844-1d80a0b146ce"
   },
   "outputs": [],
   "source": [
    "#df10.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d60472-d731-435d-8a21-ac4b5b3cbaa2",
   "metadata": {
    "id": "06d60472-d731-435d-8a21-ac4b5b3cbaa2"
   },
   "outputs": [],
   "source": [
    "#df10.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15858587-1a4f-418a-80c6-1dd7aa520078",
   "metadata": {
    "id": "15858587-1a4f-418a-80c6-1dd7aa520078"
   },
   "outputs": [],
   "source": [
    "#df10.filter(col(\"pH\") > 14).select(\"pH\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d33b2e-e513-40e5-ad3b-307b0f930b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df10.withColumn(\"pH\", when(df10[\"pH\"] == \"None\", 0)\n",
    "                                          .when(df10[\"pH\"] == \"Moderate\", 5)\n",
    "                                          .when(df10[\"pH\"] == \"Mild\", 3)\n",
    "                                          .otherwise(df10[\"pH\"].cast(\"float\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f2e0f-d65d-4c63-9dbc-02034ddde43d",
   "metadata": {
    "id": "4c2f2e0f-d65d-4c63-9dbc-02034ddde43d"
   },
   "outputs": [],
   "source": [
    "# # Convert from string to float\n",
    "df12 = df11.withColumn(\"Temperature, water\", df10[\"Temperature, water\"].cast(FloatType()))\n",
    "df13 = df12.withColumn(\"Specific conductance\", df11[\"Specific conductance\"].cast(FloatType()))\n",
    "df14 = df13.withColumn(\"pH\", df12[\"pH\"].cast(FloatType()))\n",
    "df15 = df14.withColumn(\"Oxygen\", df13[\"Oxygen\"].cast(FloatType()))\n",
    "df16 = df15.withColumn(\"HydrologicEvent\", df14[\"HydrologicEvent\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810668e-9436-48bd-9bba-ade4e5b48a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pH scale range\n",
    "min_ph = 0\n",
    "max_ph = 14\n",
    "\n",
    "# Filter out rows with pH values outside the pH scale range\n",
    "df16 = df16.filter((col(\"pH\") >= min_ph) & (col(\"pH\") <= max_ph))\n",
    "\n",
    "# Filter out rows with extreme water temperatures, i.e > 80 C\n",
    "df16 = df16.filter(col(\"Temperature, water\").cast(\"float\") <= 80)\n",
    "\n",
    "df16 = df16.filter(col(\"Specific conductance\").cast(\"float\") <= 100000)\n",
    "\n",
    "df16 = df16.filter(col(\"Oxygen\").cast(\"float\") <= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c8300-dcb8-4b63-8886-64e20901f0ae",
   "metadata": {
    "id": "817c8300-dcb8-4b63-8886-64e20901f0ae"
   },
   "outputs": [],
   "source": [
    "#df16.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e46842-c00a-4e9d-8dbf-1538d39f696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17 = df16.filter(col(\"pH\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a4129-5bee-4e09-9bef-76572a7025fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18 = df17.select(\"Temperature, water\", \"Specific conductance\", \"Oxygen\", \"HydrologicEvent\", \"pH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490974c-9c34-466a-9bd4-8a032adf877a",
   "metadata": {
    "id": "1490974c-9c34-466a-9bd4-8a032adf877a"
   },
   "outputs": [],
   "source": [
    "#df18.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33d265-5c5e-481b-9d40-be0b888dae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df18.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16607141-3aeb-4425-bad9-d24b85245836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df18.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285dcf9-3b59-4afd-a469-6d2b3e3235c5",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e88893-3343-40d5-8fc6-bafe28b5fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = pd.DataFrame(columns = [\"Model\", \"RMSE\", \"R2\", \"Method\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10678c-48b5-465a-9c59-f0fa93068d78",
   "metadata": {
    "id": "eba7def9-336b-488b-b187-a0f55d6d428a"
   },
   "source": [
    "## Method 2: Replace NULL values with mean in corresponding col AND county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6fdc9bc-a7a6-4ce8-95b6-c69f8958d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_MAKER_API_KEY = \"6618272817df1758841685bay0ce314\"\n",
    "\n",
    "# Latitude, longitude retrieval via NLDI API with USGS Code\n",
    "## Note: No request limitations\n",
    "def retrieve_coordinates(usgs_code):\n",
    "    response = requests.get('https://labs.waterdata.usgs.gov/api/nldi/linked-data/wqp/' + usgs_code)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert response to JSON format\n",
    "        if data:\n",
    "            # Accessing coordinates\n",
    "            coordinates = data['features'][0]['geometry']['coordinates']\n",
    "\n",
    "            # Storing latitude and longitude\n",
    "            latitude = str(coordinates[1])\n",
    "            longitude = str(coordinates[0])\n",
    "            return coordinates\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "        \n",
    "# Reverse geocoding via map maker API\n",
    "## Note: 1 mill request/mo for free\n",
    "def retrieve_state(coordinates):\n",
    "    if coordinates != \"NULL\":\n",
    "        latitude = str(coordinates[1])\n",
    "        longitude = str(coordinates[0])\n",
    "\n",
    "        response = requests.get(\"https://geocode.maps.co/reverse?lat=\" + latitude + \"&lon=\" + longitude + \"&api_key=\" + MAP_MAKER_API_KEY)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'state' in data['address']:\n",
    "                state = data['address']['state']\n",
    "                return state\n",
    "    return \"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2734170-4358-423b-830a-323d3461c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding state column to each individual sample in dataset\n",
    "states_column = []\n",
    "pandasDf = df17.toPandas()\n",
    "\n",
    "for index, row in pandasDf.iterrows():\n",
    "    # Access each row's data\n",
    "    monitoring_location_id = row['MonitoringLocationIdentifier']\n",
    "    coords = retrieve_coordinates(monitoring_location_id)\n",
    "    if coords == \"NULL\":\n",
    "        states_column.append(coords)\n",
    "    else:\n",
    "        state = retrieve_state(coords)\n",
    "        states_column.append(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06e18c2b-120f-42ad-b24f-c0b0e3153ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "pandasDf[\"State\"] = states_column\n",
    "spark_pandas_df = ss.createDataFrame(pandasDf)\n",
    "\n",
    "(training_data, validation_data, test_data) = spark_pandas_df.randomSplit([0.6, 0.2, 0.2], seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c10d439e-0b4f-426a-850f-d1e9b8d868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_training = training_data.toPandas()\n",
    "pandas_validation = validation_data.toPandas()\n",
    "pandas_test = test_data.toPandas()\n",
    "\n",
    "# Calculate mean values by county\n",
    "mean_values_by_state = pandas_training.groupby(\"State\").agg(\n",
    "    {\"Oxygen\": \"mean\", \"Temperature, water\": \"mean\", \"Specific conductance\": \"mean\"}\n",
    ").reset_index()\n",
    "\n",
    "# Print the mean values by county\n",
    "#print(mean_values_by_state)\n",
    "  \n",
    "for index, row in pandas_training.iterrows():\n",
    "    state = row[\"State\"]\n",
    "    for characteristic in [\"Oxygen\", \"Temperature, water\", \"Specific conductance\"]:\n",
    "        if row[characteristic] == 0:\n",
    "            if state in mean_values_by_state[\"State\"].values:\n",
    "                mean_value = mean_values_by_state.loc[mean_values_by_state[\"State\"] == state, characteristic].values[0]\n",
    "            else:\n",
    "                # If the state is not found, use the mean values for \"Null\"\n",
    "                mean_value = mean_values_by_state.loc[mean_values_by_state[\"State\"] == \"NULL\", characteristic].values[0]\n",
    "            pandas_training.at[index, characteristic] = mean_value\n",
    "    \n",
    "for index, row in pandas_validation.iterrows():\n",
    "    state = row[\"State\"]\n",
    "    for characteristic in [\"Oxygen\", \"Temperature, water\", \"Specific conductance\"]:\n",
    "        if row[characteristic] == 0:\n",
    "            if state in mean_values_by_state[\"State\"].values:\n",
    "                mean_value = mean_values_by_state.loc[mean_values_by_state[\"State\"] == state, characteristic].values[0]\n",
    "            else:\n",
    "                # If the state is not found, use the mean values for \"Null\"\n",
    "                mean_value = mean_values_by_state.loc[mean_values_by_state[\"State\"] == \"NULL\", characteristic].values[0]\n",
    "            pandas_validation.at[index, characteristic] = mean_value\n",
    "        \n",
    "for index, row in pandas_test.iterrows():\n",
    "    state = row[\"State\"]\n",
    "    for characteristic in [\"Oxygen\", \"Temperature, water\", \"Specific conductance\"]:\n",
    "        if row[characteristic] == 0:\n",
    "            if state in mean_values_by_state[\"State\"].values:\n",
    "                mean_value = mean_values_by_state.loc[mean_values_by_state[\"State\"] == state, characteristic].values[0]\n",
    "            else:\n",
    "                # If the state is not found, use the mean values for \"Null\"\n",
    "                mean_value = mean_values_by_state.loc[mean_values_by_state[\"State\"] == \"NULL\", characteristic].values[0]\n",
    "            pandas_test.at[index, characteristic] = mean_value\n",
    "        \n",
    "spark_training_df = ss.createDataFrame(pandas_training)\n",
    "spark_validation_df = ss.createDataFrame(pandas_validation)\n",
    "spark_test_df = ss.createDataFrame(pandas_test)\n",
    "\n",
    "spark_training_data = spark_training_df.select(\"Temperature, water\", \"Specific conductance\", \"Oxygen\", \"HydrologicEvent\", \"pH\")\n",
    "spark_validation_data = spark_validation_df.select(\"Temperature, water\", \"Specific conductance\", \"Oxygen\", \"HydrologicEvent\", \"pH\")\n",
    "spark_test_data = spark_test_df.select(\"Temperature, water\", \"Specific conductance\", \"Oxygen\", \"HydrologicEvent\", \"pH\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5efcd-410a-4f9c-bc61-1ff306b368cd",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "febe1d82-f20e-416d-9df7-0536f8761fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_columns = spark_training_data.columns[:-1]\n",
    "training_output_columns = spark_training_data.columns[-1]\n",
    "validation_input_columns = spark_validation_data.columns[:-1]\n",
    "validation_output_columns = spark_validation_data.columns[-1]\n",
    "test_input_columns = spark_test_data.columns[:-1]\n",
    "test_output_columns = spark_test_data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d08e7-bea2-4bf2-aacf-a6b18f058374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature vector by combining all feature columns into a single 'features' column\n",
    "training_assembler = VectorAssembler(inputCols = training_input_columns, outputCol = 'features')\n",
    "validation_assembler = VectorAssembler(inputCols = validation_input_columns, outputCol = 'features')\n",
    "test_assembler = VectorAssembler(inputCols = test_input_columns, outputCol = 'features')\n",
    "\n",
    "training_data = training_assembler.transform(spark_training_data)\n",
    "validation_data = validation_assembler.transform(spark_validation_data)\n",
    "test_data = test_assembler.transform(spark_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78bde8-2588-4268-bcad-f46ec2c8793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature vector using StandardScaler\n",
    "scaler = StandardScaler(inputCol = \"features\", outputCol = \"scaled_features\", withStd = True, withMean = True)\n",
    "\n",
    "training_scaler_model = scaler.fit(training_data)\n",
    "validation_scaler_model = scaler.fit(validation_data)\n",
    "test_scaler_model = scaler.fit(test_data)\n",
    "\n",
    "training_data = training_scaler_model.transform(training_data)\n",
    "validation_data = validation_scaler_model.transform(validation_data)\n",
    "test_data = test_scaler_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed57c4-813c-436d-b30d-193283c347f6",
   "metadata": {},
   "source": [
    "### Ridge Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e94328d-4f8d-40a8-8652-07ceacfc5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = LinearRegression(featuresCol = \"features\", labelCol = \"pH\", predictionCol = \"predicted_pH\", elasticNetParam = 0)\n",
    "lr_model = model.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0a9c42a-8f21-4eac-9392-6c3098f3a3d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "scaled_features does not exist. Available: ActivityStartDate, MonitoringLocationIdentifier, collect_list(CharacteristicName), collect_list(ResultMeasureValue), collect_list(HydrologicEvent), Temperature, water, Specific conductance, pH, Oxygen, HydrologicEvent, State",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-f6a6b6b06ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m lr_evaluator_rmse = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n\u001b[1;32m      4\u001b[0m                  labelCol = \"pH\", metricName = \"rmse\")\n\u001b[1;32m      5\u001b[0m lr_evaluator = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: scaled_features does not exist. Available: ActivityStartDate, MonitoringLocationIdentifier, collect_list(CharacteristicName), collect_list(ResultMeasureValue), collect_list(HydrologicEvent), Temperature, water, Specific conductance, pH, Oxygen, HydrologicEvent, State"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(validation_data)\n",
    "\n",
    "lr_evaluator_rmse = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"rmse\")\n",
    "lr_evaluator = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"r2\")\n",
    "\n",
    "\n",
    "\n",
    "ml_df.loc[len(ml_df)] = {\"Model\": \"Ridge Regression\", \"RMSE\": lr_evaluator_rmse.evaluate(lr_predictions), \"R2\": lr_evaluator.evaluate(lr_predictions), \"Method\": 2}\n",
    "\n",
    "#print(\"RMSE on validation data : %g\" % lr_evaluator_rmse.evaluate(lr_predictions))\n",
    "#print(\"r2 on validation data : %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ee772-2d9b-42ae-88dd-46d30878eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lr_model.coefficients.toArray().tolist()\n",
    "intercept = [lr_model.intercept]\n",
    "data = {\"Temperature, water\": coefficients[0], \"Specific conductance\": coefficients[1], \"Oxygen\": coefficients[2], \"HydrologicEvent\": coefficients[3], \"Intercept\": intercept}\n",
    "\n",
    "coefficients_df = pd.DataFrame(data)\n",
    "\n",
    "#print(coefficients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d7de0-309d-4a98-bc95-81e66cf213df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/trn5106/work/Final Project/main code/Linear_Coefficients.csv\"\n",
    "coefficients_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed49844-5257-4525-bc32-0fbaf908333f",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0dae1429-4cb9-4081-b213-7138dd743c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data : 0.506511\n",
      "r2 on test data : 0.407751\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "dt = DecisionTreeRegressor(featuresCol = \"features\", labelCol = \"pH\", predictionCol = \"predicted_pH\")\n",
    "dt_model = dt.fit(training_data)\n",
    "dt_predictions = dt_model.transform(validation_data)\n",
    "\n",
    "dt_evaluator_rmse = RegressionEvaluator(predictionCol=\"predicted_pH\", \\\n",
    "                 labelCol=\"pH\",metricName=\"rmse\")\n",
    "dt_evaluator = RegressionEvaluator(predictionCol=\"predicted_pH\", \\\n",
    "                 labelCol=\"pH\",metricName=\"r2\")\n",
    "\n",
    "ml_df.loc[len(ml_df)] = {\"Model\": \"Decision Tree\", \"RMSE\": dt_evaluator_rmse.evaluate(dt_predictions), \"R2\": dt_evaluator.evaluate(dt_predictions), \"Method\": 2}\n",
    "\n",
    "\n",
    "#print(\"RMSE on test data : %g\" % dt_evaluator_rmse.evaluate(dt_predictions))\n",
    "#print(\"r2 on test data : %g\" % dt_evaluator.evaluate(dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1178ac-9f7f-429a-9783-920464df45b3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9020e48e-e812-4d6c-8eb9-49664d32428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation data : 0.453085\n",
      "r2 on validation data : 0.5261\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol = 'pH', predictionCol = \"predicted_pH\")\n",
    "rf_model = rf.fit(training_data)\n",
    "rf_predictions = rf_model.transform(validation_data)\n",
    "\n",
    "rf_evaluator_rmse = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"rmse\")\n",
    "rf_evaluator = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"r2\")\n",
    "\n",
    "ml_df.loc[len(ml_df)] = {\"Model\": \"Random Forest\", \"RMSE\": rf_evaluator_rmse.evaluate(rf_predictions), \"R2\": rf_evaluator.evaluate(rf_predictions), \"Method\": 2}\n",
    "\n",
    "#print(\"RMSE on validation data : %g\" % rf_evaluator_rmse.evaluate(rf_predictions))\n",
    "#print(\"r2 on validation data : %g\" % rf_evaluator.evaluate(rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de969f-1e15-40ba-98ac-27bc7f630148",
   "metadata": {},
   "source": [
    "### Gradient Boosted Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1acc426-08ec-4c25-a05f-e756c4355d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation data : 0.630997\n",
      "r2 on validation data : 0.0808607\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "# Define GBTRegressor model\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'pH', predictionCol = \"predicted_pH\")\n",
    "\n",
    "# Fit the model\n",
    "gbt_model = gbt.fit(training_data)\n",
    "\n",
    "gbt_predictions = gbt_model.transform(validation_data)\n",
    "\n",
    "gbt_evaluator_rmse = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"rmse\")\n",
    "gbt_evaluator = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"r2\")\n",
    "\n",
    "ml_df.loc[len(ml_df)] = {\"Model\": \"Gradient Boosted Tree Regression\", \"RMSE\": gbt_evaluator_rmse.evaluate(gbt_predictions), \"R2\": gbt_evaluator.evaluate(gbt_predictions), \"Method\": 2}\n",
    "\n",
    "#print(\"RMSE on validation data : %g\" % gbt_evaluator_rmse.evaluate(gbt_predictions))\n",
    "#print(\"r2 on validation data : %g\" % gbt_evaluator.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bc49c-90e9-45b6-b8e9-aa5ea768b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/trn5106/work/Final Project/main code/ML_Models.csv\"\n",
    "ml_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46433149-9501-4a98-b9e6-44b0ca70fabd",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83fe6cb-d574-4678-bdc8-088d72e1163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "dt = DecisionTreeRegressor(featuresCol = \"features\", labelCol = \"pH\", predictionCol = \"predicted_pH\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1, 2, 3, 4])  # max depth of the tree\n",
    "             .addGrid(dt.minInstancesPerNode, [1, 2, 3, 4, 5])  # minimum number of instances each child must have\n",
    "             .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol = \"predicted_pH\", labelCol = \"pH\", metricName = \"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(predictionCol = \"predicted_pH\", labelCol = \"pH\", metricName = \"r2\")\n",
    "\n",
    "crossval = CrossValidator(estimator = dt,\n",
    "                          estimatorParamMaps = paramGrid,\n",
    "                          evaluator = evaluator,\n",
    "                          numFolds = 3)\n",
    "\n",
    "cvModel = crossval.fit(training_data)\n",
    "\n",
    "best_model = cvModel.bestModel\n",
    "\n",
    "best_model.save('./Best_DT')\n",
    "\n",
    "predictions = best_model.transform(validation_data)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "#print(\"RMSE on validation data : %g\" % rmse)\n",
    "#print(\"r2 on validation data : %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568061fd-ca3f-4d10-8c70-75726e8b0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{p.name: v for p, v in m.items()} for m in cvModel.getEstimatorParamMaps()]\n",
    "\n",
    "dt_hpt = pd.DataFrame.from_dict([\n",
    "    {cvModel.getEvaluator().getMetricName(): metric, **ps} \n",
    "    for ps, metric in zip(params, cvModel.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d8df3-04bd-46b3-a23e-3f6bbeb8ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/trn5106/work/Final Project/main code/DT_HPT_Local.csv\"\n",
    "dt_hpt.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf309f6-8d16-4224-9360-35d136b9d6bb",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445e173-e2fb-4b3a-832f-23fd6a0db17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = [\"Model\", \"RMSE\", \"R2\", \"Method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d98463-72da-4863-893a-8062cfee2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "dt = DecisionTreeRegressor(featuresCol = \"features\", labelCol = \"pH\", \\\n",
    "                           predictionCol = \"predicted_pH\", maxDepth = best_model.getMaxDepth(), \\\n",
    "                           minInstancesPerNode = best_model.getMinInstancesPerNode())\n",
    "dt_model = dt.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068786cb-cfb4-4709-be5c-2315eb9a1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "dt_evaluator_rmse = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"rmse\")\n",
    "dt_evaluator = RegressionEvaluator(predictionCol = \"predicted_pH\", \\\n",
    "                 labelCol = \"pH\", metricName = \"r2\")\n",
    "\n",
    "final_df.loc[len(final_df)] = {\"Model\": \"Decision Tree\", \"RMSE\": dt_evaluator_rmse.evaluate(dt_predictions), \"R2\": dt_evaluator.evaluate(dt_predictions), \"Method\": 2}\n",
    "\n",
    "#print(\"RMSE on test data : %g\" % dt_evaluator_rmse.evaluate(dt_predictions))\n",
    "#print(\"r2 on test data : %g\" % dt_evaluator.evaluate(dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be8caa-4f80-486a-bbb9-5112b1d286e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/trn5106/work/Final Project/main code/Final_Model.csv\"\n",
    "final_df.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ds410_f24)",
   "language": "python",
   "name": "ds410_sp24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
