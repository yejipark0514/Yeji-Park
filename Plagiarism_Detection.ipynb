{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yejipark0514/Yeji-Park/blob/main/Plagiarism_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxdcGDIAkr3b"
      },
      "source": [
        "# **Final project- Plagarism Detection**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v793HXKP65EJ"
      },
      "source": [
        "by Team **A9**: Namkyu Lee (nol5129), Tsung Ting Lee (tvl5472), Yeji Park (ykp5105),\n",
        "Yearin Kim(kzy5152), Yu-Cheng Cheng (ykc5277)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgiI4HiK7MMH"
      },
      "source": [
        "**Background**\n",
        "\n",
        "Plagiarism, often defined as a discrete offense, is using someone else’s work without attribution. In academic writing, plagiarism involves using words, ideas or information from a source without citing it correctly. Easy access to the Web and large databases has exacerbated plagiarism into a serious issue for educational institutions and students. Some plagiarism methods include copy-paste, paraphrasing, no proper use of quotation marks and idea and code plagiarism (Maurer et al., 2006). Paraphrasing is plagiarism if one lifes a direct phrase from another's work and changes a few words and if one does not properly credit the original author.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gnerarE7d8J"
      },
      "source": [
        "**Project Objective**\n",
        "\n",
        "There are many plagiarism checkers existing in public but reliability and validity of these tools raise serious doubts. It is possible that the checkers might fail at determining legitimate plagiarism, may report false positives for common phrases and may provide different results because each website uses different techniques. On account of that, we would like to use Jaccard similarity, Cosine similarity, Levenshtein Similarity (Edit Distance) and N-gram for heatmap to see if the paraphrased text can pass the similartiy tests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1lOXutqyY7y"
      },
      "source": [
        "## Package install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWR-zeBtxs4A",
        "outputId": "528d8014-5370-40f2-ee79-8e626a138a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.20.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 18.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.20.8 rapidfuzz-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A58ljYWAy5J",
        "outputId": "7aecb56b-3de8-4287-8bdf-59179a3e3011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5uNSfqB0IzX",
        "outputId": "5a412e2f-8065-4ecf-f680-e63fdbb4ab9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXhqsqJhTLXU"
      },
      "source": [
        "## Input file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVxkyuw1C8FV",
        "outputId": "d37ae0df-e863-4565-8aa4-b2e0c045ba09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "364\n",
            "Stopword removed: {'parallel', 'claim', 'lots', 'tasks', 'bysshe', 'returned', 'language', 'style', 'analyzer', 'really', 'exercise', 'byrons', 'work', 'summer', 'shared', 'romantic', 'analysis', 'implement', 'although', 'wonder', 'discouraged', 'meeting', 'believed', 'college', 'professor', 'boolean', 'figuresalan', 'never', 'turing', 'etc', 'much', 'improve', 'trapped', 'mit', 'teaches', 'turned', 'ever', 'formal', 'defense', 'telephone', 'close', 'electronic', 'related', 'third', 'equations', 'became', 'left', 'calculations', 'combined', 'one', 'used', 'basic', 'asking', 'knew', 'able', 'due', 'probability', 'nature', 'computable', 'made', 'called', 'scientific', 'introduced', 'shannonwe', 'earlier', 'limited', 'poetic', 'stretched', 'open', 'electromagnetic', 'programming', 'frankenstein', 'lord', 'wheels', 'charles', 'michigan', 'uncertainty', 'childhood', 'developed', 'physics', 'electrical', 'uncountable', 'cambridge', 'humanoid', 'read', 'phase', 'many', 'logical', 'shannon', 'must', 'programmed', 'engine', 'board', 'discuss', 'mostly', 'inputs', '1937', 'program', 'wasnt', 'instead', 'encourages', 'talent', 'side', 'configures', 'making', 'collaborated', 'boarding', 'everything', 'welleducated', 'sent', '201', 'two', 'british', 'pulleys', 'percy', 'lovelace', 'born', 'notice', 'four', 'according', 'precisely', 'set', 'moderate', 'aside', 'methods', 'student', 'turings', 'land', 'countable', 'advance', 'swore', 'negative', 'break', 'provable', 'lead', 'suggestions', 'packed', 'inventors', 'colonel', 'symbols', 'modern', 'could', 'blood', 'result', 'laws', 'imperfect', 'define', 'delighted', 'hilberts', 'tried', 'truefalse', 'weeks', 'question', 'operation', 'handed', 'level', 'time', 'fundamental', 'kings', 'calls', 'bernoulli', 'observation', 'rods', 'rather', 'way', 'previous', 'circuits', 'grew', 'compute', 'sherborne', 'possible', 'heredity', '90', 'tubes', 'parents', 'book', 'named', 'first', 'us', 'solved', 'polynomial', 'using', 'ago', 'route', '1931', 'minimal', 'concepts', 'concept', 'computing', 'wrote', 'differential', 'mathematician', 'love', 'sequence', 'relationship', 'answered', 'bell', 'walter', 'engineering', 'school', 'difference', 'questions', 'study', 'noble', 'infinite', '2', 'saw', 'india', 'discussed', 'think', 'babbage', 'foundations', 'mary', 'purpose', 'systems', 'realized', 'single', '1', 'qualities', 'characteristics', 'provide', 'analytical', 'years', 'subatomic', 'poem', 'problems', 'thinking', 'studied', 'uses', 'mechanically', 'faster', 'numbers', 'machine', 'machines', 'ifelse', 'ideas', 'explains', 'description', 'department', 'inherited', 'family', 'also', 'lady', 'george', 'chapter', 'adas', 'shelley', 'claude', 'solves', 'bulletin', 'respected', 'husband', 'got', 'david', 'switches', 'fascinated', 'applying', 'circuit', 'symbol', 'spirit', 'people', 'hilbert', 'nephew', 'old', 'villa', 'statement', 'find', 'proposed', 'loyalty', 'reprogrammed', 'computers', 'vacuum', 'manmade', 'thoughts', 'applied', 'handle', 'created', 'logic', 'perform', 'built', 'brother', 'behind', 'older', 'base2', 'discussing', 'use', 'appreciated', 'invented', 'mathematical', 'later', 'human', '3', 'labs', 'control', 'function', 'governed', 'seventeen', 'met', 'complete', 'table', 'determine', 'quantum', 'shows', 'offer', 'graduate', 'still', 'generalpurpose', 'product', 'mother', 'digital', 'intelligence', 'went', 'working', 'idea', 'owned', 'university', 'operations', 'free', 'full', 'cannot', 'p', 'loop', 'certainty', 'returning', 'binary', 'laid', 'reconsider', 'vannevar', 'career', 'foundation', 'mathematics', 'arise', 'bush', 'determined', 'byron', 'boole', 'relays', 'help', 'page', 'lines', 'shelleys', 'system', 'gave', 'three', 'allows', 'age', 'scholarship', 'invent', 'infinity', '32', 'scans', 'scientist', 'father', 'analog', 'ada', 'known', 'wealth', 'either', 'solve', 'took', 'five', 'calculate', 'science', 'announced'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "train_text = \"Org_file.txt\"\n",
        "test_text = \"rephrased.txt\"\n",
        "unrelated_text = \"unrelated.txt\"\n",
        "editPad = \"editpad.txt\"\n",
        "paraphraser = \"paraphraser_io.txt\"\n",
        "spinBot = \"Spinbot.txt\"\n",
        "paraphrasing_tool = \"paraphrasing_tool_com.txt\"\n",
        "prepostseo = \"prepostseo.txt\"\n",
        "\n",
        "# read training data\n",
        "\n",
        "with open(train_text) as f:\n",
        "  train_text = f.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "train_text = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", train_text)\n",
        "train_text = re.sub(r'[^\\w\\s]', \"\", train_text)\n",
        "\n",
        "with open(test_text) as r:\n",
        "    test_text = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "test_text = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", test_text)\n",
        "test_text = re.sub(r'[^\\w\\s]', \"\", test_text)\n",
        "\n",
        "with open(unrelated_text) as r:\n",
        "    unrelated_text = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "unrelated_text = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", unrelated_text)\n",
        "unrelated_text = re.sub(r'[^\\w\\s]', \"\", unrelated_text)\n",
        "\n",
        "with open(editPad) as r:\n",
        "    editPad = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "editPad = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", editPad)\n",
        "editPad = re.sub(r'[^\\w\\s]', \"\", editPad)\n",
        "\n",
        "with open(paraphraser) as r:\n",
        "    paraphraser = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "paraphraser = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", paraphraser)\n",
        "paraphraser = re.sub(r'[^\\w\\s]', \"\", paraphraser)\n",
        "\n",
        "with open(spinBot) as r:\n",
        "    spinBot = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "spinBot = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", spinBot)\n",
        "spinBot = re.sub(r'[^\\w\\s]', \"\", spinBot)\n",
        "\n",
        "with open(paraphrasing_tool) as r:\n",
        "    paraphrasing_tool = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "paraphrasing_tool = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", paraphrasing_tool)\n",
        "paraphrasing_tool = re.sub(r'[^\\w\\s]', \"\", paraphrasing_tool)\n",
        "\n",
        "with open(prepostseo) as r:\n",
        "    prepostseo = r.read().lower()\n",
        "\n",
        "# apply preprocessing (remove text inside square and curly brackets and rem punc)\n",
        "prepostseo = re.sub(r\"\\[.*\\]|\\{.*\\}\", \"\", prepostseo)\n",
        "prepostseo = re.sub(r'[^\\w\\s]', \"\", prepostseo)\n",
        "\n",
        "#tokenize the text data\n",
        "train_text_token = train_text.split()\n",
        "test_text_token = test_text.split()\n",
        "unrelated_text_token = unrelated_text.split()\n",
        "editPad_token = editPad.split()\n",
        "paraphraser_token = paraphraser.split()\n",
        "spinBot_token = spinBot.split()\n",
        "paraphrasing_tool_token = paraphrasing_tool.split()\n",
        "prepostseo_token = prepostseo.split()\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "# sw contains the list of stopwords\n",
        "sw = stopwords.words('english')\n",
        "l1 = [];l2 = [];l3 = [];l4 = [];l5 = [];l6 = [];l7 = [];l8 = [];l9 = [];l10 = [];l11 = [];l12 = [];l13 = [];l14 = [];\n",
        "\n",
        "# remove stop words from the string\n",
        "X_set = {w for w in train_text_token if not w in sw}\n",
        "Y_set = {w for w in test_text_token if not w in sw}\n",
        "Z_set = {w for w in unrelated_text_token if not w in sw}\n",
        "A_set = {w for w in editPad_token if not w in sw}\n",
        "B_set = {w for w in paraphraser_token if not w in sw}\n",
        "C_set = {w for w in spinBot_token if not w in sw}\n",
        "D_set = {w for w in paraphrasing_tool_token if not w in sw}\n",
        "E_set = {w for w in prepostseo_token if not w in sw}\n",
        "\n",
        "print(len(A_set))\n",
        "print(\"Stopword removed:\", A_set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNHGWtSIngAa"
      },
      "source": [
        "#**Methods**\n",
        "## Jaccard Similarity, Cosine similarity, and Edit Distance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIWa1eK1vRD2"
      },
      "source": [
        "#### **Jaccard Similarity**\n",
        "In this part, we use Jaccard similarity by calculating the intersection of two documents over the union of two documents.\n",
        "\n",
        "We compare the scores between the unrelated text and 6 rephrased texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "_leX_HGnu4_H",
        "outputId": "14d1d96c-093e-4161-fcce-3a47c344d41a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c8bb90f7e6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#find Jaccard Similarity between the two sets (original and unrelated)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_set' is not defined"
          ]
        }
      ],
      "source": [
        "#define Jaccard Similarity function\n",
        "def jaccard(list1, list2):\n",
        "    intersection = len(list(set(list1).intersection(list2)))\n",
        "    union = (len(list1) + len(list2)) - intersection\n",
        "    return float(intersection) / union\n",
        "\n",
        "#find Jaccard Similarity between the two sets (original and unrelated)\n",
        "jaccard(X_set, Z_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwccPChSzGjC",
        "outputId": "7c5b1ef7-4633-429f-b1e0-c6f5f4fab275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quillbot  -  0.43796992481203006\n",
            "editPad  -  0.5687103594080338\n",
            "paraphraser  -  0.504149377593361\n",
            "spinBot  -  0.2644230769230769\n",
            "paraphrasing_tool  -  0.5417515274949084\n",
            "prepostseo  -  0.4516728624535316\n"
          ]
        }
      ],
      "source": [
        "setList = [(\"Quillbot\",X_set, Y_set),\n",
        "           (\"editPad\", X_set, A_set),\n",
        "           (\"paraphraser\",X_set,B_set),\n",
        "           (\"spinBot\", X_set, C_set),\n",
        "           (\"paraphrasing_tool\", X_set,D_set),\n",
        "           (\"prepostseo\", X_set,E_set)]\n",
        "for x, y, z in setList:\n",
        "  l = jaccard(y, z)\n",
        "  print(x, \" - \", l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdk8C0Jo0lmX"
      },
      "source": [
        "#### **Cosine Similarity**\n",
        "In this part, we use cosine similarity. We transformed two input sets into 0 and 1. Then, we calculated the dot product of two vectors over the product of two normalized vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAmCMCcqx4fx",
        "outputId": "fb035a01-fbc1-402d-b7b2-e01529b8cbc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quillbot  -  0.6091924869058762\n",
            "editPad  -  0.7432301981157167\n",
            "paraphraser  -  0.7418050190515105\n",
            "spinBot  -  0.7461053740282597\n",
            "paraphrasing_tool  -  0.7266504872319705\n",
            "prepostseo  -  0.7534418865249852\n",
            "cosine similarity for unrelated essay:  0.08744931082816979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "l1 = [];l2 = [];l3 = [];l4 = [];l5 = [];l6 = [];l7 = [];l8 = [];l9 = [];l10 = [];l11 = [];l12 = [];l13 = [];l14 = [];\n",
        "# Use bag of word to create vector\n",
        "rvector = X_set.union(Y_set)\n",
        "for w in rvector:\n",
        "    if w in X_set: l1.append(1) # create a vector\n",
        "    else: l1.append(0)\n",
        "    if w in Y_set: l2.append(1)\n",
        "    else: l2.append(0)\n",
        "\n",
        "\n",
        "urvector = X_set.union(Z_set)\n",
        "for w in urvector:\n",
        "    if w in X_set: l3.append(1) # create a vector\n",
        "    else: l3.append(0)\n",
        "    if w in Z_set: l4.append(1)\n",
        "    else: l4.append(0)\n",
        "\n",
        "rvector2 = X_set.union(A_set)\n",
        "for w in rvector2:\n",
        "    if w in X_set: l5.append(1) # create a vector\n",
        "    else: l5.append(0)\n",
        "    if w in Y_set: l6.append(1)\n",
        "    else: l6.append(0)\n",
        "\n",
        "rvector3 = X_set.union(B_set)\n",
        "for w in rvector3:\n",
        "    if w in X_set: l7.append(1) # create a vector\n",
        "    else: l7.append(0)\n",
        "    if w in Y_set: l8.append(1)\n",
        "    else: l8.append(0)\n",
        "\n",
        "rvector4 = X_set.union(C_set)\n",
        "for w in rvector4:\n",
        "    if w in X_set: l9.append(1) # create a vector\n",
        "    else: l9.append(0)\n",
        "    if w in Y_set: l10.append(1)\n",
        "    else: l10.append(0)\n",
        "\n",
        "rvector5 = X_set.union(D_set)\n",
        "for w in rvector5:\n",
        "    if w in X_set: l11.append(1) # create a vector\n",
        "    else: l11.append(0)\n",
        "    if w in Y_set: l12.append(1)\n",
        "    else: l12.append(0)\n",
        "\n",
        "rvector6 = X_set.union(E_set)\n",
        "for w in rvector6:\n",
        "    if w in X_set: l13.append(1) # create a vector\n",
        "    else: l13.append(0)\n",
        "    if w in Y_set: l14.append(1)\n",
        "    else: l14.append(0)\n",
        "# calculate the cosine similarity\n",
        "rcosine = dot(l1, l2)/(norm(l1)*norm(l2))\n",
        "urcosine = dot(l3, l4)/(norm(l3)*norm(l4))\n",
        "rcosine2 = dot(l5, l6)/(norm(l5)*norm(l6))\n",
        "rcosine3 = dot(l7, l8)/(norm(l7)*norm(l8))\n",
        "rcosine4 = dot(l9, l10)/(norm(l9)*norm(l10))\n",
        "rcosine5 = dot(l11, l12)/(norm(l11)*norm(l12))\n",
        "rcosine6 = dot(l13, l14)/(norm(l13)*norm(l14))\n",
        "\n",
        "file_list = [(\"Quillbot\",rcosine),\n",
        "             (\"editPad\", rcosine2),\n",
        "             (\"paraphraser\",rcosine3),\n",
        "             (\"spinBot\", rcosine4),\n",
        "             (\"paraphrasing_tool\", rcosine5),\n",
        "             (\"prepostseo\", rcosine6)]\n",
        "\n",
        "for x, y in file_list:\n",
        "  # print(\"cosine similarity for paraphrasing using \", x, \" is:\", y)\n",
        "  print(x, \" - \", y)\n",
        "print(\"cosine similarity for unrelated essay: \", urcosine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNKbSVzap77q"
      },
      "source": [
        "#### **Edit Distance similarity ratio**\n",
        "Edit distance is another way to detect the similarity between texts. In this package, we use token_set_ratio function. It does not punish the sorting, and it takes out the common tokens before calculate the edit distance. The function return a score from 0 to 100. The higher the score is, the more similar the two texts are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r__mrEBIp2E-",
        "outputId": "d9974645-891e-42d5-a512-a56594a50ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score: 79\n"
          ]
        }
      ],
      "source": [
        "import fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# similarity score for original text and rephrased text\n",
        "ratio = fuzz.token_set_ratio(X_set, Y_set)\n",
        "print('Similarity score: {}'.format(ratio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2jz_Xlxp5Uv",
        "outputId": "f87215ae-704f-49c3-8972-5d2fd987b2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score: 45\n"
          ]
        }
      ],
      "source": [
        "# similarity score for original text and unrelated text\n",
        "ratio = fuzz.token_set_ratio(X_set, Z_set)\n",
        "print('Similarity score: {}'.format(ratio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg7Rewka09Mx",
        "outputId": "3bc770d3-37ee-4745-9443-4c1993f60143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quillbot  -  79\n",
            "editPad  -  85\n",
            "paraphraser  -  83\n",
            "spinBot  -  69\n",
            "paraphrasing_tool  -  85\n",
            "prepostseo  -  81\n"
          ]
        }
      ],
      "source": [
        "for x, y, z in setList:\n",
        "  l = fuzz.token_set_ratio(y, z)\n",
        "  print(x, \" - \", l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZyxAVaGooxq"
      },
      "source": [
        "\n",
        "\n",
        "# **Visualization**\n",
        "NLP (nltk) & N-gram (heatmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxyLyFPUhyh",
        "outputId": "cd18e70c-e83a-4fe4-f41c-422de97e6887"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2ATJjJsUOJ7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.util import ngrams, pad_sequence, everygrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.lm import MLE, WittenBellInterpolated\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import statistics as st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QelBHz8QXDc"
      },
      "source": [
        "## **Train file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDZl7KZEUGPJ",
        "outputId": "15c6cf1d-5333-48a0-950e-16527b650130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of ngrams: 4154\n",
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 444 items>\n"
          ]
        }
      ],
      "source": [
        "# Choose the n-gram number\n",
        "n = 4\n",
        "\n",
        "# Pad the text and tokenize\n",
        "training_data = list(pad_sequence(word_tokenize(train_text),\n",
        "                                  n,pad_left=True,left_pad_symbol=\"<s>\"))\n",
        "\n",
        "# Generate ngram based on ngram number\n",
        "ngrams = list(everygrams(training_data, max_len=n))\n",
        "print(\"Number of ngrams:\", len(ngrams))\n",
        "\n",
        "# Build N-gram Language Model\n",
        "model = WittenBellInterpolated(n)\n",
        "model.fit([ngrams], vocabulary_text=training_data)\n",
        "print(model.vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79fSv6koQbNG"
      },
      "source": [
        "## **Test file**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhhmaH4WUz0f",
        "outputId": "610c7e03-e7a0-4fa3-fb4a-efe4c79ba28a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of test data: 1010\n"
          ]
        }
      ],
      "source": [
        "# Tokenize test file\n",
        "testing_data = list(pad_sequence(word_tokenize(test_text), n,\n",
        "                                 pad_left=True,\n",
        "                                 left_pad_symbol=\"<s>\"))\n",
        "print(\"Length of test data:\", len(testing_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og-J53VOU2I-",
        "outputId": "1517c0be-1c88-4898-8316-a67d996a5aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Width, Height: 8 , 127\n",
            "0.1870091792774967\n"
          ]
        }
      ],
      "source": [
        "# Assign Scores\n",
        "scores = []\n",
        "for i, item in enumerate(testing_data[n-1:]):\n",
        "    b = model.score(item, testing_data[i:i+n-1])\n",
        "    scores.append(b)\n",
        "\n",
        "scores_np = np.array(scores)\n",
        "\n",
        "# Set Width and Height\n",
        "width = 8\n",
        "height = np.ceil(len(testing_data)/width).astype(\"int32\")\n",
        "print(\"Width, Height:\", width, \",\", height)\n",
        "\n",
        "# Copy scores to rectangular blank array\n",
        "z = np.zeros(width*height)\n",
        "z[:len(scores_np)] = scores_np\n",
        "diff = len(z) - len(scores_np)\n",
        "\n",
        "# Apply gaussian smoothing for aesthetics\n",
        "z = gaussian_filter(z, sigma=1.0)\n",
        "\n",
        "# Reshape to fit rectangle\n",
        "z = z.reshape(-1, width)\n",
        "\n",
        "# Format labels\n",
        "labels = [\" \".join(testing_data[i:i+width]) for i in range(n-1, len(testing_data), width)]\n",
        "labels_individual = [x.split() for x in labels]\n",
        "labels_individual[-1] += [\"\"]*diff\n",
        "labels = [f\"{x:60.60}\" for x in labels]\n",
        "\n",
        "print(st.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heatmap"
      ],
      "metadata": {
        "id": "Te5xKb1NhicN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MKsl9wwpU4wl",
        "outputId": "afdee410-9419-4042-c9c4-1e0aa85412ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f08c96a5-ad41-4cac-bfea-dc21a53bb72a\" class=\"plotly-graph-div\" style=\"height:3556px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f08c96a5-ad41-4cac-bfea-dc21a53bb72a\")) {                    Plotly.newPlot(                        \"f08c96a5-ad41-4cac-bfea-dc21a53bb72a\",                        [{\"colorscale\":[[0.0,\"rgb(255, 198, 196)\"],[0.16666666666666666,\"rgb(244, 163, 168)\"],[0.3333333333333333,\"rgb(227, 129, 145)\"],[0.5,\"rgb(204, 96, 125)\"],[0.6666666666666666,\"rgb(173, 70, 108)\"],[0.8333333333333334,\"rgb(139, 48, 88)\"],[1.0,\"rgb(103, 32, 68)\"]],\"customdata\":[[\"chapter\",\"1\",\"ada\",\"byron\",\"commonly\",\"known\",\"as\",\"ada\"],[\"lovelace\",\"had\",\"a\",\"wealthy\",\"but\",\"unfulfilled\",\"upbringing\",\"adas\"],[\"mother\",\"lady\",\"byron\",\"only\",\"packed\",\"up\",\"and\",\"left\"],[\"adas\",\"father\",\"lord\",\"byron\",\"with\",\"ada\",\"when\",\"she\"],[\"was\",\"five\",\"weeks\",\"old\",\"because\",\"of\",\"a\",\"poem\"],[\"that\",\"lord\",\"byron\",\"penned\",\"comparing\",\"their\",\"relationship\",\"to\"],[\"two\",\"parallel\",\"lines\",\"continued\",\"to\",\"infinity\",\"side\",\"by\"],[\"side\",\"but\",\"never\",\"to\",\"meet\",\"walter\",\"2014\",\"p34\"],[\"ada\",\"was\",\"left\",\"to\",\"grow\",\"up\",\"with\",\"her\"],[\"mother\",\"as\",\"a\",\"result\",\"never\",\"experiencing\",\"the\",\"affection\"],[\"of\",\"her\",\"father\",\"ada\",\"received\",\"both\",\"the\",\"romantic\"],[\"and\",\"mathematical\",\"features\",\"from\",\"her\",\"parents\",\"as\",\"the\"],[\"offspring\",\"of\",\"lord\",\"byron\",\"who\",\"is\",\"gifted\",\"in\"],[\"poetry\",\"and\",\"lady\",\"byron\",\"who\",\"is\",\"gifted\",\"in\"],[\"math\",\"and\",\"science\",\"ada\",\"eventually\",\"developed\",\"her\",\"poetical\"],[\"science\",\"walter\",\"2014\",\"p\",\"32\",\"style\",\"of\",\"applied\"],[\"science\",\"adas\",\"mother\",\"attempted\",\"to\",\"tame\",\"the\",\"romantic\"],[\"traits\",\"she\",\"received\",\"from\",\"her\",\"father\",\"by\",\"having\"],[\"ada\",\"take\",\"math\",\"lessons\",\"but\",\"due\",\"to\",\"the\"],[\"nature\",\"of\",\"inheritance\",\"ada\",\"still\",\"possesses\",\"these\",\"traits\"],[\"ada\",\"initially\",\"encountered\",\"charles\",\"babbage\",\"a\",\"mathematician\",\"and\"],[\"scientist\",\"who\",\"created\",\"the\",\"difference\",\"engine\",\"a\",\"device\"],[\"that\",\"resolves\",\"polynomial\",\"equations\",\"when\",\"she\",\"was\",\"seventeen\"],[\"according\",\"to\",\"walter\",\"2014\",\"babbages\",\"invention\",\"won\",\"ada\"],[\"over\",\"but\",\"she\",\"disapproved\",\"of\",\"lady\",\"byrons\",\"depiction\"],[\"of\",\"the\",\"difference\",\"engine\",\"as\",\"a\",\"thinking\",\"machine\"],[\"walter\",\"2014\",\"p32\",\"and\",\"believed\",\"that\",\"a\",\"machine\"],[\"could\",\"never\",\"reason\",\"until\",\"she\",\"read\",\"mary\",\"shelleys\"],[\"novel\",\"frankenstein\",\"which\",\"she\",\"and\",\"her\",\"husband\",\"percy\"],[\"bysshe\",\"shelley\",\"wrote\",\"while\",\"stranded\",\"in\",\"a\",\"villa\"],[\"with\",\"lord\",\"byron\",\"the\",\"story\",\"of\",\"the\",\"scientist\"],[\"who\",\"created\",\"frankenstein\",\"a\",\"machine\",\"that\",\"resembled\",\"a\"],[\"human\",\"being\",\"is\",\"told\",\"in\",\"the\",\"novel\",\"and\"],[\"this\",\"book\",\"caused\",\"ada\",\"to\",\"rethink\",\"her\",\"previous\"],[\"assertion\",\"and\",\"examine\",\"the\",\"question\",\"can\",\"manmade\",\"machines\"],[\"ever\",\"truly\",\"think\",\"2014\",\"walter\",\"p\",\"32\",\"later\"],[\"in\",\"life\",\"ada\",\"collaborated\",\"with\",\"babbage\",\"to\",\"improve\"],[\"the\",\"difference\",\"machine\",\"or\",\"to\",\"be\",\"more\",\"precise\"],[\"ada\",\"proposed\",\"the\",\"analytical\",\"machine\",\"a\",\"device\",\"for\"],[\"making\",\"calculations\",\"of\",\"any\",\"kind\",\"babbage\",\"had\",\"adas\"],[\"whole\",\"allegiance\",\"and\",\"respected\",\"both\",\"her\",\"intelligence\",\"and\"],[\"the\",\"ideas\",\"she\",\"had\",\"to\",\"offer\",\"ada\",\"had\"],[\"the\",\"following\",\"ideas\",\"and\",\"conceptions\",\"for\",\"the\",\"analytical\"],[\"machine\",\"the\",\"machine\",\"should\",\"be\",\"able\",\"to\",\"solve\"],[\"any\",\"function\",\"regardless\",\"of\",\"its\",\"complexity\",\"and\",\"it\"],[\"shouldnt\",\"be\",\"restricted\",\"to\",\"working\",\"with\",\"only\",\"numbers\"],[\"and\",\"symbols\",\"after\",\"coming\",\"up\",\"with\",\"a\",\"solution\"],[\"to\",\"the\",\"first\",\"two\",\"problems\",\"we\",\"created\",\"a\"],[\"software\",\"to\",\"calculate\",\"bernoulli\",\"numbers\",\"these\",\"ideas\",\"laid\"],[\"the\",\"groundwork\",\"for\",\"the\",\"analytical\",\"machine\",\"and\",\"gave\"],[\"the\",\"name\",\"ada\",\"to\",\"the\",\"cuttingedge\",\"programming\",\"language\"],[\"created\",\"by\",\"the\",\"us\",\"defense\",\"department\",\"chapter\",\"2\"],[\"we\",\"will\",\"first\",\"go\",\"through\",\"the\",\"four\",\"characteristics\"],[\"that\",\"describe\",\"contemporary\",\"computing\",\"before\",\"diving\",\"into\",\"the\"],[\"three\",\"protagonists\",\"alan\",\"turing\",\"vannevar\",\"bush\",\"and\",\"claude\"],[\"shannon\",\"1\",\"rather\",\"than\",\"being\",\"analog\",\"the\",\"device\"],[\"should\",\"be\",\"digital\",\"2\",\"the\",\"computer\",\"should\",\"use\"],[\"binary\",\"base2\",\"digits\",\"to\",\"carry\",\"out\",\"logical\",\"operations\"],[\"like\",\"ifelse\",\"truefalse\",\"etc\",\"3\",\"to\",\"function\",\"more\"],[\"quickly\",\"the\",\"machine\",\"should\",\"be\",\"electronic\",\"using\",\"electronic\"],[\"circuits\",\"like\",\"vacuum\",\"tubes\",\"4\",\"the\",\"device\",\"should\"],[\"be\",\"programmable\",\"and\",\"reprogrammable\",\"for\",\"a\",\"variety\",\"of\"],[\"uses\",\"turing\",\"was\",\"born\",\"into\",\"a\",\"british\",\"gentry\"],[\"family\",\"that\",\"had\",\"little\",\"fortune\",\"and\",\"no\",\"land\"],[\"because\",\"most\",\"of\",\"the\",\"familys\",\"assets\",\"were\",\"under\"],[\"the\",\"branch\",\"of\",\"his\",\"nephew\",\"when\",\"turing\",\"turned\"],[\"one\",\"his\",\"parents\",\"left\",\"him\",\"and\",\"his\",\"older\"],[\"brother\",\"in\",\"the\",\"care\",\"of\",\"a\",\"colonel\",\"and\"],[\"returned\",\"to\",\"india\",\"for\",\"a\",\"while\",\"turing\",\"was\"],[\"enrolled\",\"at\",\"sherborne\",\"boarding\",\"school\",\"after\",\"his\",\"parents\"],[\"left\",\"turing\",\"received\",\"a\",\"scholarship\",\"to\",\"kings\",\"college\"],[\"in\",\"cambridge\",\"in\",\"1931\",\"after\",\"winning\",\"it\",\"at\"],[\"sherborne\",\"the\",\"discovery\",\"that\",\"everything\",\"is\",\"regulated\",\"by\"],[\"probability\",\"rather\",\"than\",\"laws\",\"of\",\"certainty\",\"at\",\"the\"],[\"subatomic\",\"level\",\"captured\",\"his\",\"attention\",\"during\",\"his\",\"time\"],[\"in\",\"college\",\"he\",\"thought\",\"that\",\"this\",\"uncertainty\",\"allowed\"],[\"people\",\"to\",\"have\",\"free\",\"will\",\"and\",\"that\",\"it\"],[\"also\",\"showed\",\"there\",\"were\",\"some\",\"mathematical\",\"issues\",\"that\"],[\"were\",\"indeterminate\",\"and\",\"could\",\"not\",\"be\",\"addressed\",\"mechanically\"],[\"three\",\"essential\",\"problems\",\"about\",\"any\",\"formal\",\"systems\",\"in\"],[\"mathematics\",\"were\",\"put\",\"out\",\"by\",\"renowned\",\"mathematician\",\"david\"],[\"hilbert\",\"at\",\"the\",\"time\",\"and\",\"they\",\"were\",\"hotly\"],[\"debated\",\"and\",\"turing\",\"was\",\"inspired\",\"to\",\"create\",\"the\"],[\"logical\",\"computing\",\"computer\",\"popularly\",\"known\",\"as\",\"the\",\"turing\"],[\"machine\",\"by\",\"the\",\"third\",\"question\",\"is\",\"there\",\"a\"],[\"technique\",\"that\",\"can\",\"decide\",\"if\",\"a\",\"proposition\",\"is\"],[\"provable\",\"or\",\"not\",\"the\",\"turing\",\"machine\",\"uses\",\"a\"],[\"table\",\"of\",\"binary\",\"symbols\",\"to\",\"scan\",\"and\",\"configure\"],[\"itself\",\"before\",\"producing\",\"any\",\"computations\",\"for\",\"numbers\",\"that\"],[\"can\",\"be\",\"computed\",\"or\",\"can\",\"not\",\"be\",\"computed\"],[\"and\",\"this\",\"explains\",\"why\",\"there\",\"are\",\"no\",\"techniques\"],[\"that\",\"can\",\"predict\",\"in\",\"advance\",\"a\",\"collection\",\"of\"],[\"inputs\",\"that\",\"will\",\"cause\",\"the\",\"machine\",\"to\",\"enter\"],[\"an\",\"infinite\",\"loop\",\"that\",\"provided\",\"a\",\"negative\",\"response\"],[\"to\",\"david\",\"hilberts\",\"third\",\"query\",\"as\",\"turing\",\"asserted\"],[\"that\",\"it\",\"is\",\"possible\",\"to\",\"create\",\"a\",\"single\"],[\"machine\",\"that\",\"can\",\"calculate\",\"any\",\"computable\",\"sequence\",\"the\"],[\"turing\",\"machine\",\"also\",\"organized\",\"the\",\"fundamentals\",\"of\",\"the\"],[\"general\",\"purpose\",\"machine\",\"claude\",\"shannon\",\"and\",\"vannevar\",\"bush\"],[\"were\",\"two\",\"other\",\"pioneers\",\"active\",\"at\",\"the\",\"time\"],[\"at\",\"the\",\"university\",\"of\",\"michigan\",\"shannona\",\"graduate\",\"student\"],[\"at\",\"mitwas\",\"majoring\",\"in\",\"electrical\",\"engineering\",\"and\",\"mathematics\"],[\"he\",\"applied\",\"after\",\"reading\",\"a\",\"helpwanted\",\"ad\",\"on\"],[\"a\",\"bulletin\",\"board\",\"and\",\"was\",\"given\",\"the\",\"opportunity\"],[\"to\",\"work\",\"with\",\"vannevar\",\"bush\",\"at\",\"mit\",\"on\"],[\"bushs\",\"differential\",\"analyzer\",\"a\",\"device\",\"with\",\"a\",\"lot\"],[\"of\",\"electromagnetic\",\"relays\",\"that\",\"enable\",\"the\",\"control\",\"circuit\"],[\"to\",\"open\",\"and\",\"close\",\"but\",\"few\",\"rods\",\"pulleys\"],[\"or\",\"wheels\",\"shannon\",\"spent\",\"some\",\"time\",\"working\",\"with\"],[\"professor\",\"bush\",\"before\",\"taking\",\"a\",\"vacation\",\"and\",\"spending\"],[\"the\",\"summer\",\"of\",\"1937\",\"at\",\"bell\",\"labs\",\"he\"],[\"observed\",\"a\",\"phone\",\"system\",\"architecture\",\"at\",\"bell\",\"labs\"],[\"that\",\"routed\",\"calls\",\"using\",\"electrical\",\"switches\",\"he\",\"then\"],[\"made\",\"a\",\"connection\",\"between\",\"this\",\"idea\",\"and\",\"the\"],[\"logic\",\"framework\",\"created\",\"almost\",\"90\",\"years\",\"ago\",\"by\"],[\"british\",\"mathematician\",\"george\",\"boole\",\"he\",\"understood\",\"that\",\"the\"],[\"differential\",\"analyzer\",\"may\",\"carry\",\"out\",\"a\",\"series\",\"of\"],[\"logical\",\"tasks\",\"by\",\"applying\",\"the\",\"logical\",\"operations\",\"from\"],[\"boole\",\"to\",\"electrical\",\"circuits\",\"when\",\"he\",\"got\",\"back\"],[\"to\",\"mit\",\"he\",\"told\",\"bush\",\"about\",\"his\",\"discovery\"],[\"and\",\"used\",\"the\",\"differential\",\"analyzer\",\"to\",\"put\",\"this\"],[\"machines\",\"design\",\"at\",\"the\",\"foundation\",\"of\",\"all\",\"modern\"],[\"digital\",\"computers\",\"the\",\"turing\",\"machine\",\"which\",\"uses\",\"binary\"],[\"symbols\",\"to\",\"configure\",\"the\",\"computer\",\"in\",\"order\",\"to\"],[\"handle\",\"not\",\"just\",\"mathematical\",\"but\",\"also\",\"logical\",\"processes\"],[\"is\",\"related\",\"to\",\"shannons\",\"idea\",\"as\",\"well\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]],\"dx\":1,\"hovertemplate\":\"%{customdata} <br><b>Score:%{z:.3f}<extra></extra>\",\"x0\":0,\"y\":[\"chapter 1 ada byron commonly known as ada                   \",\"lovelace had a wealthy but unfulfilled upbringing adas      \",\"mother lady byron only packed up and left                   \",\"adas father lord byron with ada when she                    \",\"was five weeks old because of a poem                        \",\"that lord byron penned comparing their relationship to      \",\"two parallel lines continued to infinity side by            \",\"side but never to meet walter 2014 p34                      \",\"ada was left to grow up with her                            \",\"mother as a result never experiencing the affection         \",\"of her father ada received both the romantic                \",\"and mathematical features from her parents as the           \",\"offspring of lord byron who is gifted in                    \",\"poetry and lady byron who is gifted in                      \",\"math and science ada eventually developed her poetical      \",\"science walter 2014 p 32 style of applied                   \",\"science adas mother attempted to tame the romantic          \",\"traits she received from her father by having               \",\"ada take math lessons but due to the                        \",\"nature of inheritance ada still possesses these traits      \",\"ada initially encountered charles babbage a mathematician an\",\"scientist who created the difference engine a device        \",\"that resolves polynomial equations when she was seventeen   \",\"according to walter 2014 babbages invention won ada         \",\"over but she disapproved of lady byrons depiction           \",\"of the difference engine as a thinking machine              \",\"walter 2014 p32 and believed that a machine                 \",\"could never reason until she read mary shelleys             \",\"novel frankenstein which she and her husband percy          \",\"bysshe shelley wrote while stranded in a villa              \",\"with lord byron the story of the scientist                  \",\"who created frankenstein a machine that resembled a         \",\"human being is told in the novel and                        \",\"this book caused ada to rethink her previous                \",\"assertion and examine the question can manmade machines     \",\"ever truly think 2014 walter p 32 later                     \",\"in life ada collaborated with babbage to improve            \",\"the difference machine or to be more precise                \",\"ada proposed the analytical machine a device for            \",\"making calculations of any kind babbage had adas            \",\"whole allegiance and respected both her intelligence and    \",\"the ideas she had to offer ada had                          \",\"the following ideas and conceptions for the analytical      \",\"machine the machine should be able to solve                 \",\"any function regardless of its complexity and it            \",\"shouldnt be restricted to working with only numbers         \",\"and symbols after coming up with a solution                 \",\"to the first two problems we created a                      \",\"software to calculate bernoulli numbers these ideas laid    \",\"the groundwork for the analytical machine and gave          \",\"the name ada to the cuttingedge programming language        \",\"created by the us defense department chapter 2              \",\"we will first go through the four characteristics           \",\"that describe contemporary computing before diving into the \",\"three protagonists alan turing vannevar bush and claude     \",\"shannon 1 rather than being analog the device               \",\"should be digital 2 the computer should use                 \",\"binary base2 digits to carry out logical operations         \",\"like ifelse truefalse etc 3 to function more                \",\"quickly the machine should be electronic using electronic   \",\"circuits like vacuum tubes 4 the device should              \",\"be programmable and reprogrammable for a variety of         \",\"uses turing was born into a british gentry                  \",\"family that had little fortune and no land                  \",\"because most of the familys assets were under               \",\"the branch of his nephew when turing turned                 \",\"one his parents left him and his older                      \",\"brother in the care of a colonel and                        \",\"returned to india for a while turing was                    \",\"enrolled at sherborne boarding school after his parents     \",\"left turing received a scholarship to kings college         \",\"in cambridge in 1931 after winning it at                    \",\"sherborne the discovery that everything is regulated by     \",\"probability rather than laws of certainty at the            \",\"subatomic level captured his attention during his time      \",\"in college he thought that this uncertainty allowed         \",\"people to have free will and that it                        \",\"also showed there were some mathematical issues that        \",\"were indeterminate and could not be addressed mechanically  \",\"three essential problems about any formal systems in        \",\"mathematics were put out by renowned mathematician david    \",\"hilbert at the time and they were hotly                     \",\"debated and turing was inspired to create the               \",\"logical computing computer popularly known as the turing    \",\"machine by the third question is there a                    \",\"technique that can decide if a proposition is               \",\"provable or not the turing machine uses a                   \",\"table of binary symbols to scan and configure               \",\"itself before producing any computations for numbers that   \",\"can be computed or can not be computed                      \",\"and this explains why there are no techniques               \",\"that can predict in advance a collection of                 \",\"inputs that will cause the machine to enter                 \",\"an infinite loop that provided a negative response          \",\"to david hilberts third query as turing asserted            \",\"that it is possible to create a single                      \",\"machine that can calculate any computable sequence the      \",\"turing machine also organized the fundamentals of the       \",\"general purpose machine claude shannon and vannevar bush    \",\"were two other pioneers active at the time                  \",\"at the university of michigan shannona graduate student     \",\"at mitwas majoring in electrical engineering and mathematics\",\"he applied after reading a helpwanted ad on                 \",\"a bulletin board and was given the opportunity              \",\"to work with vannevar bush at mit on                        \",\"bushs differential analyzer a device with a lot             \",\"of electromagnetic relays that enable the control circuit   \",\"to open and close but few rods pulleys                      \",\"or wheels shannon spent some time working with              \",\"professor bush before taking a vacation and spending        \",\"the summer of 1937 at bell labs he                          \",\"observed a phone system architecture at bell labs           \",\"that routed calls using electrical switches he then         \",\"made a connection between this idea and the                 \",\"logic framework created almost 90 years ago by              \",\"british mathematician george boole he understood that the   \",\"differential analyzer may carry out a series of             \",\"logical tasks by applying the logical operations from       \",\"boole to electrical circuits when he got back               \",\"to mit he told bush about his discovery                     \",\"and used the differential analyzer to put this              \",\"machines design at the foundation of all modern             \",\"digital computers the turing machine which uses binary      \",\"symbols to configure the computer in order to               \",\"handle not just mathematical but also logical processes     \",\"is related to shannons idea as well                         \"],\"z\":[[0.7236113030132483,0.7627621735140593,0.739796359666284,0.5468794445045759,0.26873327673443087,0.2268900696438204,0.3829372474036381,0.48804379881663124],[0.623770897546146,0.7443628257345509,0.614538780502871,0.2735782751215426,0.05520982789283143,0.006647917672558953,0.018348516207199867,0.09279137115097458],[0.24217020699491226,0.40883628588134624,0.438120318540912,0.255115617740145,0.20300601209934618,0.38125920600419805,0.5293303642235694,0.47217587693921526],[0.2537731904348298,0.14440310556526542,0.23295714723546426,0.3309046932023454,0.20636482007245732,0.06154208381282338,0.015261743248311387,0.011622051504076482],[0.06626583322920956,0.2629833604113238,0.5316058226499544,0.5366186750913582,0.26034210953757086,0.06935963939846182,0.025889677889092466,0.016703634824032663],[0.04940345708634302,0.19685737935546763,0.32064367181932274,0.19630322136518377,0.07056578982609746,0.1254955854238222,0.20215629285793235,0.12696925167597406],[0.05655804900089736,0.12433233253838986,0.201919650613931,0.1335658764452554,0.08850774979423598,0.24569424896686526,0.5468626071233633,0.7390183537245587],[0.783898891802401,0.7914432080125938,0.7906448194708842,0.7876847068271308,0.8018013398772066,0.8327089234974235,0.797351630929865,0.5826147137414163],[0.2604803649247036,0.07607558923924611,0.029068057843018316,0.05873854299093642,0.23897929421352546,0.5373982676528923,0.6997245744245906,0.6753796105003422],[0.5131290632251924,0.2522697975118104,0.09124414814209156,0.032400861309788406,0.00988141235648303,0.013776200881016417,0.02247185392836145,0.019173120040274792],[0.020196477767807183,0.04000961804974364,0.05683395746234791,0.03686752843464113,0.03923599004729567,0.15935369268925798,0.37472904142813507,0.5395288721627496],[0.6106126466719741,0.4996964951299398,0.23997256433391798,0.13067249549362006,0.18878489569167411,0.18785095427897308,0.10283254238337969,0.047851331610363534],[0.03012287122741892,0.06778699269380084,0.23364386998220657,0.3667845685011607,0.2205433458106217,0.05109478254176582,0.007707730571365734,0.005700607981605785],[0.010630976277565724,0.04909627341648162,0.1806174524124564,0.28517523706624115,0.17190233538748773,0.04032681498638151,0.007671481553944566,0.016950980755071846],[0.07469439188838681,0.19683526298140724,0.2476148015135134,0.13371811446240495,0.029442534484915614,0.00786907147692274,0.01948064080661912,0.031003563884377534],[0.04406284797818309,0.12541703991134803,0.20075241983693445,0.12387559942855547,0.05732979038465995,0.1576205325288728,0.3721372243232601,0.5259668103995513],[0.49131504350491195,0.2963346471535148,0.1626349258881153,0.08151096528404589,0.03198676632467157,0.023452064290028555,0.028520011403116934,0.022213825439951606],[0.008938962557110573,0.003772741756676107,0.018604699250610073,0.09166767235036645,0.22909291175598384,0.3584433344046756,0.35972901225791754,0.18378453509198264],[0.043804402004847476,0.007440710107057429,0.0023734698640681465,0.00484609632156567,0.041648368799729135,0.2044118052955175,0.46014392694428763,0.5685479299226588],[0.5839084182887921,0.6502158733498453,0.5364298301349005,0.24071432979525823,0.05873531410358355,0.012046017559198053,0.003147834058263273,0.004105405903480598],[0.006265525880811828,0.006080227234832842,0.03066682694180817,0.15221103438074282,0.3360479949030255,0.3456549635584462,0.1675532732834152,0.05259476555031449],[0.06762086309655302,0.10298347919586175,0.07168271994670977,0.06277200120050988,0.15709663034108645,0.23451241689526445,0.14031264243727762,0.035772249594141575],[0.011909242615600037,0.03153964055351667,0.12245133253832749,0.20015400010104561,0.12173868937658032,0.028320964104328526,0.006060435589021046,0.029099375966147395],[0.12776199318627235,0.23349301303741915,0.2466255359305106,0.22820417972080115,0.12383966839850036,0.027819770711534488,0.004502279901522301,0.0035853008759507677],[0.0026125791013759765,0.001630467738956333,0.0021859536073533235,0.006882337951559429,0.020406235116560728,0.05471961933303268,0.08337727520310137,0.06230154164937653],[0.06319316501818784,0.13393285781834538,0.2973583221312962,0.49818939804046064,0.5934669611344074,0.6129445866826564,0.47106673025260004,0.22677385197258004],[0.17469916715487022,0.2780083368857437,0.2861721469367419,0.2182773531286472,0.20493053597500013,0.25264529590328144,0.26310791865013416,0.2467304427574661],[0.13370930031232103,0.03255472270395703,0.03312254639768111,0.15558780438513264,0.3514040816202918,0.37076480875814816,0.17845119388980477,0.03620669772623221],[0.003736753839558576,0.0021729000621092944,0.003308840382678581,0.00847284899284085,0.03471992060298193,0.13806387696083472,0.3855423951213579,0.6787527313693288],[0.7881442782205061,0.6095441169624899,0.26340119259284256,0.05279563931508968,0.012949463142608138,0.052258544050072124,0.20331761068537144,0.4768241517711975],[0.7113495463412792,0.7730817472326349,0.6140743501137202,0.27919945922030415,0.06932161120601658,0.04829506215416337,0.07430409205598129,0.09545666178853673],[0.10797176437807793,0.06312076727728465,0.023109603638620916,0.034461202690424464,0.07211165250675693,0.08516603699175415,0.05234269196452336,0.023874734702928113],[0.010217532717404294,0.004257132028389444,0.004773909668335332,0.011549856242953205,0.03569323351320918,0.05544720785058671,0.04281981811013528,0.04300077832606725],[0.07728071251147242,0.09467525041632224,0.05738582095511087,0.028994094060015532,0.02459046984095313,0.014612904069673013,0.006033823539095499,0.003979980102055902],[0.008442873630239827,0.015576166019213088,0.020543172016915388,0.0236171588289164,0.02166907901079484,0.0676055319040784,0.26461800738797936,0.5772203132969549],[0.7466280176889395,0.6018906532795977,0.2629166739135455,0.052130720053349025,0.00461093488024452,0.00042699664325743193,0.000805436932455824,0.00288684461303745],[0.012284701403103499,0.04412268663676335,0.07111779014620805,0.05006932447860566,0.05417027045459488,0.15459628610014323,0.23579507021881252,0.15325518578079694],[0.07855495386655245,0.1422366085630951,0.3540278647893298,0.6089135798619447,0.7341193950935823,0.6922368297225633,0.48618944392606667,0.20540179159105265],[0.05859508509971908,0.06840800979163697,0.2133973389470381,0.472233768200643,0.5782842687118909,0.3666458457789108,0.11925597659312823,0.02159708915043977],[0.004034472928406688,0.0036183051805656805,0.005218047392343489,0.0037820632892019567,0.0022691024237673518,0.002365601667238579,0.0018728204389304734,0.0011261652703152538],[0.0014728249119735576,0.004301469895621036,0.006645809250944687,0.0046298869429404884,0.005839371221077603,0.01868770960210652,0.03191213783374193,0.02982727729607938],[0.02332975949635026,0.013198005578892585,0.0047174666889061335,0.0037894298605130787,0.00574921557037285,0.008379120395457526,0.015506596699857815,0.019605489421704377],[0.013913439092888825,0.018869832476363434,0.06579637612477302,0.10812704208722128,0.08080059299777803,0.09242085494396636,0.20014499478596626,0.37040804250336673],[0.4542809274435093,0.29483288232613997,0.2358264059499296,0.4201258300627706,0.5747780276297925,0.5973560523738335,0.5592588294164645,0.48108213781577547],[0.5434151661214861,0.49921271650425014,0.23534931619241767,0.054862819140567995,0.010862555899015032,0.00905390121745436,0.012908236648591833,0.008332188895011255],[0.004065199358459217,0.005437181077687929,0.010297476679036816,0.01439294907671941,0.010904760610692421,0.017250795116726857,0.08398049001746544,0.27268252457169495],[0.47488839219793394,0.4312270802739768,0.19259911750826703,0.05083036538414355,0.06150351701665179,0.09898208957241142,0.06844489787874947,0.03165901133786869],[0.0367164875761358,0.04272598193964091,0.02302940514369757,0.0054364138022207215,0.0011696504117697517,0.0016722186884012475,0.005024514687581199,0.009276034442114195],[0.012665554748515143,0.016769179469272085,0.03819040265433418,0.1559438983868023,0.3456784045352133,0.36112648358826116,0.1752593266450406,0.047549941393570536],[0.025390837619631387,0.029241709144687086,0.08091144646180821,0.1991315946252944,0.3693133062517198,0.445808983036035,0.24963632510848616,0.06675315004533132],[0.02662622218097034,0.019499611250805283,0.0231794879602542,0.0339901590966708,0.03211757239824451,0.040370112392680166,0.12407126456455127,0.20082323111924621],[0.12877556842063245,0.07789186967764175,0.2056960241470175,0.47855077647518585,0.6882854823868684,0.6021717123839008,0.32340484083946003,0.1678203569572139],[0.15736644689207943,0.25537158939443794,0.295121752077311,0.15778361577854683,0.04605513668366009,0.026562368248040633,0.01804014517420266,0.00792039317765635],[0.004431847030739521,0.0022860091349432106,0.0009885289621776746,0.0010806621949835283,0.0020536630815496085,0.01521704346150924,0.08203998378355687,0.21142283420342017],[0.2578698051273172,0.1643681255699961,0.18368104710212307,0.38504495779654563,0.5970391364439878,0.723646640481383,0.7181498362458003,0.6829651146394717],[0.5574319751253789,0.25900392817296036,0.05247983209976848,0.0043367453109180295,0.0017854059492840681,0.006891433275021154,0.01389106250596917,0.04231757497655328],[0.1629793818979204,0.28691112807288266,0.2298146745977658,0.1692725449471213,0.17862823572375752,0.10402945723667156,0.025215932311388238,0.003965031402720046],[0.0016677982143027603,0.0025405720830910038,0.008300428958763366,0.013510404637957801,0.010069970772204923,0.02328553868370701,0.09307244812263421,0.15125509315333552],[0.0914935350254301,0.020720757931778928,0.002078513534698991,0.0014781111938027326,0.004869186550018494,0.007318868088940649,0.004719440879409164,0.004668681768122167],[0.021652439239570685,0.0782975066571919,0.21392837164511833,0.40958781866126037,0.44334997713461727,0.23387557285159072,0.11797096913614197,0.23589215439683991],[0.33224623153825017,0.21567161262544074,0.16381243968039347,0.21828155574661595,0.18844685379785492,0.1405179570701853,0.1043967903255195,0.16919241498412496],[0.2545381841753902,0.15983863460022818,0.04770503726859175,0.02138769943529712,0.04559510437008443,0.07023297583127298,0.04669323975455612,0.019215281006406074],[0.014833994723637521,0.04818542584856764,0.16409964026700863,0.4023234728661172,0.6692736746734793,0.7626289260453858,0.7210950450892692,0.6892714573621355],[0.554174011591527,0.25291403332813084,0.05146480287380329,0.006160754042516517,0.008741264546165414,0.02203106611152234,0.04866574497322119,0.06884278103157469],[0.04251448577839693,0.022051880239149054,0.04326110516008033,0.0605436468400752,0.034720738702443306,0.008376683278016678,0.003311226484499532,0.007378062650736904],[0.011542265363744256,0.009472828155771384,0.006589620978913676,0.004864262482360724,0.015326713008495549,0.06281439747289819,0.10259329226900718,0.062296315790866516],[0.014603587581751051,0.002432863890115456,0.0014774587982965257,0.0027065287906521563,0.011576124395542339,0.05131699721036356,0.198273425997275,0.4429436612411944],[0.4936076821946496,0.27371448098323237,0.10236371083626955,0.042726052743572655,0.029494950660920775,0.06457210910395861,0.19723902257330697,0.30751052091722786],[0.19238788400394607,0.09565455103573937,0.23902759301706178,0.5034326476517743,0.5305591141408956,0.28962124754989693,0.10267195831387693,0.05252405144779624],[0.031974112730998844,0.031166718631573213,0.0629001534468785,0.14200699081413318,0.2046326769287027,0.12242006061195215,0.02846016876194801,0.003859779257275642],[0.002467586821113594,0.004660808237182096,0.011138968213777418,0.01902734851832513,0.019185060932756612,0.038980025353460575,0.16166904381941788,0.3935821636426569],[0.5566696712945203,0.48660746261866794,0.2342071772572121,0.0657737916375432,0.016835140663347615,0.004018423936569058,0.006193865171719487,0.02281396045592337],[0.03775957174811835,0.02674142958155757,0.011976506307073987,0.008459939716105196,0.006404806669523212,0.005163265583632675,0.007210101757412457,0.0158043047814533],[0.020995980739906207,0.014074700233819428,0.03264556805523536,0.15202727127640772,0.3293630970268374,0.34348540541007355,0.2297400376013809,0.225856624888327],[0.3476986824266969,0.4055721629856892,0.2232345014641512,0.05095699669554519,0.019572895669896007,0.06312115693570249,0.10183943595202403,0.06253833018424099],[0.016171799438002656,0.003730325624304237,0.0028647466092248065,0.007670053009532652,0.04265112964386367,0.152329734301619,0.23367027735487383,0.13995792007905763],[0.038763794445286257,0.018278824530651827,0.03814538627522082,0.1554716560982739,0.3437482677560144,0.3594789075878757,0.17869639208212143,0.04765542812110904],[0.011881847293438207,0.010857713944386997,0.036627913389322225,0.05853255894861549,0.0356165450075951,0.009504064992349993,0.005364798193171681,0.007473903013623117],[0.006413659207663902,0.008973811200387677,0.014293967509580471,0.024242915810740596,0.07328425727873453,0.11659090815510922,0.07052873314099406,0.016264106959609722],[0.001976885652163924,0.0012976244216194774,0.010368930557301736,0.0660946924698954,0.23855424867169012,0.5177727734883041,0.7454186378818008,0.7770581938507806],[0.5664712883484222,0.23619395991653946,0.04587970080658231,0.006092528848368428,0.004572678196474488,0.0062669434410079555,0.03802755762731988,0.1638878217931398],[0.2815257000104237,0.22714009612429603,0.14416941289409688,0.07174609987530059,0.02107775314626147,0.0057376541870354306,0.002185382593305023,0.0025191235288917558],[0.008580611869107697,0.019505704241264202,0.03473612236458493,0.045658177688778355,0.03356842924261612,0.021981797412192354,0.024081275029830977,0.04564991532383442],[0.09826059780726691,0.1336012500863886,0.08035087570080512,0.05502881966198821,0.18331575601105948,0.38253327483499727,0.5109080388438609,0.6329383456544654],[0.5746215284729161,0.28777291168331404,0.13488453911278475,0.26852748836240453,0.5124255000869519,0.6188273637140755,0.6506048906616572,0.5292867919533071],[0.2455380322630437,0.08395138576130498,0.05899453645854702,0.03397301607659818,0.015872134476439585,0.01597653366781952,0.017585855846941084,0.0638119795384309],[0.25035737381166656,0.5066230654070213,0.5086587750557184,0.29204126366263,0.2708421406576841,0.35287266674343487,0.21524289746801115,0.10087198350832216],[0.24169940901388487,0.5391101216554286,0.7416222493330182,0.8057970973770676,0.7523549451047638,0.6722677882223957,0.6774546444370494,0.538235267779557],[0.23206377662328642,0.04593675645983235,0.0147353506754043,0.0726497038859996,0.23300135928467508,0.3315535129255863,0.19743711385974774,0.07503460614835687],[0.05650951076233799,0.032298693317635956,0.008667550288077142,0.009731782736156701,0.05592097453721549,0.18851586931845493,0.278412745776107,0.1716531188093436],[0.07120207075705527,0.07946087195977955,0.09505180412257772,0.06874656615175129,0.09891516116023046,0.19234159939538736,0.19622675530171108,0.10241991586616589],[0.05610296039472144,0.057564990779159546,0.040722537193706054,0.06502710444901952,0.20808147736072452,0.31772284575298265,0.19687843115382722,0.10012137438665578],[0.24166153370387738,0.4915823799207215,0.4897217448706237,0.24363647944608052,0.09492146669846789,0.06565296202267566,0.03625417028299395,0.03832736800399993],[0.16276212912134447,0.3815886245224228,0.42114343719102676,0.21139838442855519,0.05209377858980308,0.018234797532723026,0.01077220036284993,0.01016449056143785],[0.013811205913263309,0.008607496215003283,0.0025513682348463997,0.0017799339594267221,0.006015291807477447,0.017759448547853232,0.025761931257971177,0.023260023106125086],[0.06171234981330989,0.24426083876101012,0.5412145604459034,0.70181512236513,0.5787111120140979,0.2704767855948028,0.11348374350191373,0.2461112641910609],[0.5268944166598812,0.6398885559542536,0.47341554304579314,0.20428971048457478,0.102552672144068,0.20604712543379847,0.28830073862313227,0.21899433898794024],[0.27000924070313154,0.39953777390698875,0.28927752206098034,0.11092842686553342,0.08276469965314388,0.24617075299719562,0.5308233254994785,0.6815878293324718],[0.7104958168466129,0.7441278651258274,0.6331779276680575,0.4447765199143837,0.44030624059468765,0.5266478247107124,0.6416077778575511,0.5770434263701145],[0.2695002593042615,0.054469116458677344,0.004574333619603659,0.001780052047243616,0.01631650827455233,0.0678902652612193,0.11009190683440116,0.08151007828843329],[0.09412203937413882,0.20136204129041854,0.3870133578581731,0.5893621560457151,0.5268067053671249,0.2616643566932719,0.20680257887879275,0.3853085780803688],[0.42127695679589666,0.20956850860938342,0.04628246340004444,0.020296461973439893,0.08451304735676182,0.2509891503611481,0.3435003161904384,0.19692519611878623],[0.058691280425981665,0.030044455589218387,0.0180889645671069,0.013323441386473126,0.018566251227285047,0.01616882527940639,0.022899853375389377,0.09792583815217512],[0.27761869138185774,0.4794483896837912,0.4875186787153539,0.24272020972221509,0.05311841373609695,0.011554845818454488,0.012918929953059634,0.018344999164987857],[0.05621025557936454,0.21203211268453634,0.49363234353608737,0.7196392063185484,0.7835016463000766,0.7078756399021764,0.5213179234038281,0.26034709525073235],[0.21724495097596647,0.4495735285904481,0.6230913055442224,0.4910166784025174,0.2081275594070268,0.06022401105038584,0.07377817830148861,0.24452698314918156],[0.5403052251945689,0.7441566613935222,0.7853329017239592,0.6088558139185882,0.27980722683838094,0.11971937745568001,0.25384821383150014,0.562501548058888],[0.7663798044754824,0.80749762625944,0.7664015997744562,0.55848713781426,0.23606554454395412,0.07235452786172367,0.1250536986512618,0.2001438184750472],[0.12164019940825976,0.027855537139201532,0.003144918915939369,0.0006164087153399745,0.00039935227539497056,0.001132866184617033,0.007336834847645191,0.05217065093146424],[0.1978826926820385,0.3090164904201489,0.18580244549562938,0.04974506640395178,0.019640839152782013,0.016856451646841415,0.017638905219203815,0.02470714339154658],[0.06974961732092476,0.2412263143758793,0.4909400473330995,0.4985118130779701,0.3145568060894963,0.3499513460139946,0.5049470699452319,0.4013366749038325],[0.16781353069054372,0.08634427926224113,0.19850898439134765,0.3063179872639931,0.1973977729215416,0.132156055312446,0.2871900235219383,0.39622911407659717],[0.2251451130113607,0.05024462853981629,0.01434171673593812,0.06324442659712604,0.19250230668432303,0.26720341314626456,0.1646416163294383,0.06777806256027197],[0.06304909879010447,0.07750054126886648,0.04554100126454843,0.012236665837120169,0.0061664169824827385,0.012003870648040349,0.02302449344359996,0.024068772859446544],[0.011729226365595494,0.002696205206599998,0.002934833335296818,0.03029026140908756,0.15541734812706964,0.3514918747597774,0.37219221752925935,0.1927459365801696],[0.0997565547437016,0.13056750406458698,0.18240374192357456,0.2140387238414065,0.12415317752489238,0.03321085277047756,0.020151317255815954,0.0686473278599451],[0.2377114850784267,0.37277345469502643,0.22339248430503333,0.05158724046557245,0.013013601471458539,0.016131152943271606,0.018264177594439882,0.04759287786219724],[0.1519156268194079,0.23231411596740803,0.14114803972129308,0.04694387887574891,0.05630049274766964,0.16911092041459513,0.3923638733532076,0.5725435610377172],[0.5082814925292831,0.2665050948587223,0.1945234528196819,0.24102398545420456,0.14338516822826863,0.034539897182599186,0.01847937614422389,0.06839631659885759],[0.1403462496423832,0.20959026081564475,0.2501834516026652,0.14449898444360618,0.03404647484676552,0.004939573551395723,0.0031743518016536998,0.008479950092767514],[0.015851115482653545,0.025807760736474582,0.07798348395940781,0.244343745402203,0.37535852990898855,0.22550747921470238,0.052752630912864334,0.007926861475819754],[0.003914012637287854,0.016268187576324797,0.07013050808454369,0.1499497052572189,0.2504663683027578,0.3189097188265315,0.1880924245953193,0.056360040857701216],[0.06583310308699222,0.10991430285029527,0.1242159195429729,0.25377804670120874,0.4367828760424035,0.49334664707837944,0.6129045502878778,0.7759306553357933],[0.8296826903777013,0.7572886882223056,0.642359358187945,0.5131806056163264,0.2627662602911153,0.1449807977485409,0.2975419666611748,0.41425078000610127],[0.23693399083315336,0.05308394690466141,0.005698380670664515,0.0017313632194556196,0.0020667146123761397,0.002287608399102544,0.0021538983045972784,0.0029364998135649033],[0.005402400492699083,0.010272700607975303,0.014054514190005982,0.00915323908773762,0.007207782307258968,0.016595975602108997,0.022685577323466648,0.012774390859901008],[0.002769793375996433,0.00022492622965519427,6.749438712541544e-06,0.0,0.0,0.0,0.0,0.0]],\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"family\":\"Courier New\"},\"height\":3556,\"width\":1000,\"yaxis\":{\"autorange\":\"reversed\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f08c96a5-ad41-4cac-bfea-dc21a53bb72a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create heatmap for visualization\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                z=z, x0=0, dx=1,\n",
        "                y=labels, zmin=0, zmax=1,\n",
        "                customdata=labels_individual,\n",
        "                hovertemplate='%{customdata} <br><b>Score:%{z:.3f}<extra></extra>',\n",
        "                colorscale=\"burg\"))\n",
        "fig.update_layout({\"height\":height*28, \"width\":1000, \"font\":{\"family\":\"Courier New\"}})\n",
        "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FwSHfCLd9kH"
      },
      "source": [
        "In the heatmap, we can distinguish the similarity part in the text. The darker the color in the heatmap, the more similar the texts are. It is a useful visualization tool to check the similarity part and corrrect the indicated part to prevent plagiarism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PXSPgkaua5E"
      },
      "source": [
        "### Results\n",
        "\n",
        "**Unrelated text results:**\n",
        "*   Jaccard similarity: 0.043\n",
        "*   Cosine similarity: 0.087\n",
        "*   Edit Distance: 45\n",
        "---------------------\n",
        "**Paraphrasing tools**\n",
        "\n",
        "**Quillbot:**\n",
        "*   Jaccard similarity: 0.438\n",
        "*   Cosine similarity: 0.609\n",
        "*   Edit Distance: 79\n",
        "\n",
        "**editPad:**\n",
        "*   Jaccard similarity:  0.569\n",
        "*   Cosine similarity: 0.743\n",
        "*   Edit Distance: 85\n",
        "\n",
        "**paraphraser:**\n",
        "*   Jaccard similarity: 0.504\n",
        "*   Cosine similarity: 0.742\n",
        "*   Edit Distance: 83\n",
        "\n",
        "**spinBot:**\n",
        "*   Jaccard similarity: 0.264\n",
        "*   Cosine similarity: 0.746\n",
        "*   Edit Distance: 69\n",
        "\n",
        "**paraphrasing_tool:**\n",
        "*   Jaccard similarity: 0.542\n",
        "*   Cosine similarity: 0.727\n",
        "*   Edit Distance: 85\n",
        "\n",
        "**prepostseo:**\n",
        "*   Jaccard similarity: 0.452\n",
        "*   Cosine similarity: 0.753\n",
        "*   Edit Distance: 81\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "The results showed that text with paraphrasing has a much higher similarity score in all similarity measures. Unrelated text will only have a small value of similarity score. We can conclude that both Jaccard and Cosine similarity measurements are suitable for plagiarism checking. Each similarity measurement has its strength and weakness. When considering duplicate terms in the document, Jaccard similarity will only count the term once. However, Cosine similarity will consider duplicates. In future work, we could use different similarity measurements depending on different situations. We also believe that Edit distance is a good measurement for plagiarism. Nowadays, people plagiarize other's work by inserting, deleting, and substituting words, and edit distance calculate score for it. Some researchers also study using edit distance for a plagiarism checking system and produce good results.\n",
        "\n",
        "To sum up, there are more similarity measurements for plagiarism detection. In this work, we prove that by only using the three most basic similarity measurements, we can distinguish paraphrasing text created by different paraphrasing websites."
      ],
      "metadata": {
        "id": "DYN39MtESlRL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYz0pxo5qvJr"
      },
      "source": [
        "Works Cited\n",
        "\n",
        "Maurer, Hermann & Kappe, Frank & Zaka, Bilal. (2006). Plagiarism - A Survey. Journal of Universal Computer Science. 12. 1050-1084.\n",
        "https://www.researchgate.net/publication/220017646_Plagiarism_-_A_Survey/link/0912f514817642d96e000000/download\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}